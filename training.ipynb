{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:22:51.910516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 19:22:53.425182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import librosa\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data.json\"\n",
    "\n",
    "VAL_SIZE = 0.2 # percentage of dataset\n",
    "TEST_SIZE = 0.1 # percentage of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from json file\n",
    "\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "X = np.array(data[\"mfcc\"])\n",
    "y = np.array(data[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=VAL_SIZE)\n",
    "\n",
    "# add an axis to input sets to match the shape CNN expects (last axis is like channel in color images)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "X_validation = X_validation[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:23:50.877065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.040508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.041106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.042715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.043202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.043591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.229890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.230343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.230361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 19:23:51.230744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 19:23:51.230780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2875 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "# choose hyperparameters to tune\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    model.add(keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    fit_log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=fit_log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(x=X_train,\n",
    "              y=y_train,\n",
    "              validation_data=(X_validation, y_validation),\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              callbacks=[tensorboard_callback])\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:24:00.539052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2023-12-18 19:24:00.831160: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-18 19:24:01.170637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4d0001840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-18 19:24:01.170720: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 970, Compute Capability 5.2\n",
      "2023-12-18 19:24:01.206595: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-18 19:24:01.585497: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-18 19:24:01.676418: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 8s 17ms/step - loss: 1.7213 - accuracy: 0.3921 - val_loss: 1.4956 - val_accuracy: 0.4498\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.1864 - accuracy: 0.5853 - val_loss: 1.5532 - val_accuracy: 0.4639\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9605 - accuracy: 0.6612 - val_loss: 1.6599 - val_accuracy: 0.4858\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.8189 - accuracy: 0.7097 - val_loss: 1.1079 - val_accuracy: 0.6401\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.7118 - accuracy: 0.7552 - val_loss: 1.0396 - val_accuracy: 0.6578\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6149 - accuracy: 0.7862 - val_loss: 0.8295 - val_accuracy: 0.7317\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.5637 - accuracy: 0.8038 - val_loss: 0.9300 - val_accuracy: 0.7128\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5117 - accuracy: 0.8214 - val_loss: 0.7376 - val_accuracy: 0.7476\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4556 - accuracy: 0.8378 - val_loss: 0.8198 - val_accuracy: 0.7264\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4180 - accuracy: 0.8559 - val_loss: 0.8206 - val_accuracy: 0.7417\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4052 - accuracy: 0.8599 - val_loss: 0.6887 - val_accuracy: 0.7849\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3632 - accuracy: 0.8719 - val_loss: 1.1043 - val_accuracy: 0.6962\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3531 - accuracy: 0.8788 - val_loss: 0.6295 - val_accuracy: 0.8014\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3224 - accuracy: 0.8855 - val_loss: 0.9016 - val_accuracy: 0.7405\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3341 - accuracy: 0.8836 - val_loss: 0.9211 - val_accuracy: 0.7447\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2983 - accuracy: 0.8973 - val_loss: 0.7845 - val_accuracy: 0.7931\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2596 - accuracy: 0.9115 - val_loss: 0.8889 - val_accuracy: 0.7541\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2732 - accuracy: 0.9057 - val_loss: 0.7669 - val_accuracy: 0.7665\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2709 - accuracy: 0.9078 - val_loss: 0.8052 - val_accuracy: 0.7742\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2546 - accuracy: 0.9111 - val_loss: 0.7264 - val_accuracy: 0.7985\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2478 - accuracy: 0.9133 - val_loss: 0.8092 - val_accuracy: 0.7754\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2359 - accuracy: 0.9162 - val_loss: 0.9782 - val_accuracy: 0.7618\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2189 - accuracy: 0.9270 - val_loss: 0.8296 - val_accuracy: 0.7772\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2045 - accuracy: 0.9276 - val_loss: 0.7988 - val_accuracy: 0.7772\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2055 - accuracy: 0.9286 - val_loss: 1.0035 - val_accuracy: 0.7600\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2242 - accuracy: 0.9235 - val_loss: 0.8986 - val_accuracy: 0.7801\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.1922 - accuracy: 0.9338 - val_loss: 0.9222 - val_accuracy: 0.7849\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.2070 - accuracy: 0.9272 - val_loss: 0.8535 - val_accuracy: 0.7878\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1934 - accuracy: 0.9316 - val_loss: 0.8248 - val_accuracy: 0.7872\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1689 - accuracy: 0.9424 - val_loss: 0.7788 - val_accuracy: 0.8168\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7711 - accuracy: 0.8106\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 5s 18ms/step - loss: 1.8857 - accuracy: 0.3344 - val_loss: 2.0850 - val_accuracy: 0.3322\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.4336 - accuracy: 0.4938 - val_loss: 1.4240 - val_accuracy: 0.5030\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.2317 - accuracy: 0.5663 - val_loss: 1.4647 - val_accuracy: 0.5183\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.1086 - accuracy: 0.6117 - val_loss: 1.1157 - val_accuracy: 0.6330\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.0073 - accuracy: 0.6486 - val_loss: 1.0043 - val_accuracy: 0.6578\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9333 - accuracy: 0.6758 - val_loss: 1.5462 - val_accuracy: 0.5100\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.8586 - accuracy: 0.7018 - val_loss: 1.0519 - val_accuracy: 0.6554\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.8073 - accuracy: 0.7200 - val_loss: 1.0229 - val_accuracy: 0.6413\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.7470 - accuracy: 0.7435 - val_loss: 0.9311 - val_accuracy: 0.6791\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.7041 - accuracy: 0.7538 - val_loss: 0.8606 - val_accuracy: 0.7305\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.6531 - accuracy: 0.7702 - val_loss: 0.9304 - val_accuracy: 0.6933\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6283 - accuracy: 0.7843 - val_loss: 0.9135 - val_accuracy: 0.7222\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5930 - accuracy: 0.8020 - val_loss: 0.8415 - val_accuracy: 0.7340\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5722 - accuracy: 0.8035 - val_loss: 1.1733 - val_accuracy: 0.6348\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5362 - accuracy: 0.8155 - val_loss: 0.8655 - val_accuracy: 0.7329\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5160 - accuracy: 0.8220 - val_loss: 0.8256 - val_accuracy: 0.7258\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4911 - accuracy: 0.8317 - val_loss: 0.9610 - val_accuracy: 0.7086\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4599 - accuracy: 0.8423 - val_loss: 0.8290 - val_accuracy: 0.7382\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4529 - accuracy: 0.8437 - val_loss: 0.7637 - val_accuracy: 0.7512\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4349 - accuracy: 0.8441 - val_loss: 1.3474 - val_accuracy: 0.6212\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4081 - accuracy: 0.8568 - val_loss: 1.0698 - val_accuracy: 0.6791\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3741 - accuracy: 0.8715 - val_loss: 0.8198 - val_accuracy: 0.7441\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3532 - accuracy: 0.8794 - val_loss: 0.8938 - val_accuracy: 0.7252\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3451 - accuracy: 0.8821 - val_loss: 0.6779 - val_accuracy: 0.7878\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.3466 - accuracy: 0.8831 - val_loss: 1.0581 - val_accuracy: 0.6939\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3330 - accuracy: 0.8849 - val_loss: 0.6334 - val_accuracy: 0.7896\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3040 - accuracy: 0.8983 - val_loss: 0.8047 - val_accuracy: 0.7530\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3053 - accuracy: 0.8958 - val_loss: 0.8219 - val_accuracy: 0.7571\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2893 - accuracy: 0.9017 - val_loss: 0.7451 - val_accuracy: 0.7660\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2848 - accuracy: 0.9048 - val_loss: 1.1199 - val_accuracy: 0.7033\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9392 - accuracy: 0.7255\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.3, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 17ms/step - loss: 1.9315 - accuracy: 0.3338 - val_loss: 1.4953 - val_accuracy: 0.4764\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.4133 - accuracy: 0.5022 - val_loss: 1.3609 - val_accuracy: 0.5337\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.2109 - accuracy: 0.5700 - val_loss: 1.1134 - val_accuracy: 0.6087\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.0611 - accuracy: 0.6306 - val_loss: 1.0537 - val_accuracy: 0.6448\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.9904 - accuracy: 0.6495 - val_loss: 0.8989 - val_accuracy: 0.7039\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.8795 - accuracy: 0.6930 - val_loss: 0.9935 - val_accuracy: 0.6726\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.8406 - accuracy: 0.7023 - val_loss: 1.4023 - val_accuracy: 0.5532\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.7541 - accuracy: 0.7371 - val_loss: 0.9785 - val_accuracy: 0.6814\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7262 - accuracy: 0.7401 - val_loss: 0.8488 - val_accuracy: 0.7181\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6673 - accuracy: 0.7609 - val_loss: 0.8257 - val_accuracy: 0.7258\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6445 - accuracy: 0.7676 - val_loss: 1.0793 - val_accuracy: 0.6779\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6118 - accuracy: 0.7858 - val_loss: 0.8321 - val_accuracy: 0.7453\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5917 - accuracy: 0.7962 - val_loss: 0.7661 - val_accuracy: 0.7518\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5559 - accuracy: 0.8057 - val_loss: 0.8519 - val_accuracy: 0.7482\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5142 - accuracy: 0.8171 - val_loss: 0.8381 - val_accuracy: 0.7642\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4996 - accuracy: 0.8248 - val_loss: 0.7917 - val_accuracy: 0.7417\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4959 - accuracy: 0.8245 - val_loss: 0.7957 - val_accuracy: 0.7807\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4790 - accuracy: 0.8293 - val_loss: 0.6462 - val_accuracy: 0.8014\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4379 - accuracy: 0.8463 - val_loss: 0.7925 - val_accuracy: 0.7813\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4368 - accuracy: 0.8391 - val_loss: 0.6080 - val_accuracy: 0.8044\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4410 - accuracy: 0.8431 - val_loss: 0.5927 - val_accuracy: 0.8233\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4349 - accuracy: 0.8463 - val_loss: 0.7053 - val_accuracy: 0.7896\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4281 - accuracy: 0.8465 - val_loss: 0.6218 - val_accuracy: 0.7973\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3789 - accuracy: 0.8621 - val_loss: 0.8555 - val_accuracy: 0.7766\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3888 - accuracy: 0.8598 - val_loss: 0.6945 - val_accuracy: 0.7955\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3759 - accuracy: 0.8633 - val_loss: 0.8097 - val_accuracy: 0.7790\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3698 - accuracy: 0.8647 - val_loss: 0.7300 - val_accuracy: 0.8032\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3585 - accuracy: 0.8684 - val_loss: 0.6201 - val_accuracy: 0.8227\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3328 - accuracy: 0.8784 - val_loss: 0.8139 - val_accuracy: 0.7701\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3548 - accuracy: 0.8749 - val_loss: 0.7448 - val_accuracy: 0.8050\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7290 - accuracy: 0.8234\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.3, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 5s 18ms/step - loss: 2.1272 - accuracy: 0.2762 - val_loss: 1.7261 - val_accuracy: 0.3848\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.6157 - accuracy: 0.4314 - val_loss: 1.4075 - val_accuracy: 0.5095\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.4203 - accuracy: 0.5031 - val_loss: 1.4890 - val_accuracy: 0.5071\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.2749 - accuracy: 0.5507 - val_loss: 1.1060 - val_accuracy: 0.6324\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.1664 - accuracy: 0.5960 - val_loss: 1.1827 - val_accuracy: 0.6164\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.1003 - accuracy: 0.6189 - val_loss: 1.1237 - val_accuracy: 0.6277\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.0383 - accuracy: 0.6333 - val_loss: 1.0507 - val_accuracy: 0.6353\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9607 - accuracy: 0.6609 - val_loss: 0.9097 - val_accuracy: 0.6927\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.9348 - accuracy: 0.6659 - val_loss: 1.0689 - val_accuracy: 0.6217\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9024 - accuracy: 0.6760 - val_loss: 0.9669 - val_accuracy: 0.6726\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.8472 - accuracy: 0.7012 - val_loss: 0.8848 - val_accuracy: 0.7086\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.8106 - accuracy: 0.7104 - val_loss: 1.0373 - val_accuracy: 0.6596\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7731 - accuracy: 0.7256 - val_loss: 0.8837 - val_accuracy: 0.7228\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.7559 - accuracy: 0.7278 - val_loss: 0.7357 - val_accuracy: 0.7612\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7120 - accuracy: 0.7450 - val_loss: 0.6999 - val_accuracy: 0.7713\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7080 - accuracy: 0.7484 - val_loss: 0.9854 - val_accuracy: 0.6738\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.6854 - accuracy: 0.7525 - val_loss: 1.2161 - val_accuracy: 0.6158\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6626 - accuracy: 0.7694 - val_loss: 0.6285 - val_accuracy: 0.7973\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6396 - accuracy: 0.7744 - val_loss: 0.8736 - val_accuracy: 0.7258\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.6363 - accuracy: 0.7769 - val_loss: 0.7778 - val_accuracy: 0.7577\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6147 - accuracy: 0.7791 - val_loss: 0.9903 - val_accuracy: 0.6820\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.5953 - accuracy: 0.7880 - val_loss: 0.7246 - val_accuracy: 0.7600\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5734 - accuracy: 0.7930 - val_loss: 1.0997 - val_accuracy: 0.6678\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5779 - accuracy: 0.7909 - val_loss: 1.8271 - val_accuracy: 0.5804\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5560 - accuracy: 0.7998 - val_loss: 0.8161 - val_accuracy: 0.7447\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5480 - accuracy: 0.8051 - val_loss: 0.8640 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5144 - accuracy: 0.8122 - val_loss: 0.6310 - val_accuracy: 0.7955\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5035 - accuracy: 0.8132 - val_loss: 0.7810 - val_accuracy: 0.7447\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5057 - accuracy: 0.8177 - val_loss: 0.8303 - val_accuracy: 0.7364\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4895 - accuracy: 0.8220 - val_loss: 0.7173 - val_accuracy: 0.7754\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6565 - accuracy: 0.7830\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 7s 17ms/step - loss: 1.6588 - accuracy: 0.4269 - val_loss: 1.9768 - val_accuracy: 0.3197\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.0342 - accuracy: 0.6460 - val_loss: 1.6961 - val_accuracy: 0.5024\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.7897 - accuracy: 0.7268 - val_loss: 1.0571 - val_accuracy: 0.6590\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.6448 - accuracy: 0.7741 - val_loss: 0.7558 - val_accuracy: 0.7476\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5334 - accuracy: 0.8112 - val_loss: 0.8698 - val_accuracy: 0.7240\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4708 - accuracy: 0.8375 - val_loss: 0.9295 - val_accuracy: 0.6980\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4302 - accuracy: 0.8506 - val_loss: 0.7414 - val_accuracy: 0.7648\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3489 - accuracy: 0.8757 - val_loss: 0.7440 - val_accuracy: 0.7612\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3333 - accuracy: 0.8815 - val_loss: 0.8708 - val_accuracy: 0.7465\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2793 - accuracy: 0.9054 - val_loss: 0.8774 - val_accuracy: 0.7494\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2745 - accuracy: 0.9090 - val_loss: 1.1001 - val_accuracy: 0.7080\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2408 - accuracy: 0.9164 - val_loss: 0.8556 - val_accuracy: 0.7535\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2291 - accuracy: 0.9193 - val_loss: 0.9236 - val_accuracy: 0.7411\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2074 - accuracy: 0.9310 - val_loss: 1.2682 - val_accuracy: 0.6838\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2031 - accuracy: 0.9359 - val_loss: 0.7816 - val_accuracy: 0.7914\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1914 - accuracy: 0.9350 - val_loss: 0.8247 - val_accuracy: 0.7719\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.1949 - accuracy: 0.9323 - val_loss: 0.8231 - val_accuracy: 0.7831\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1682 - accuracy: 0.9408 - val_loss: 1.0859 - val_accuracy: 0.7417\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1641 - accuracy: 0.9441 - val_loss: 0.9253 - val_accuracy: 0.7618\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1546 - accuracy: 0.9474 - val_loss: 0.9141 - val_accuracy: 0.7671\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1262 - accuracy: 0.9574 - val_loss: 0.8236 - val_accuracy: 0.7955\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1363 - accuracy: 0.9549 - val_loss: 0.7507 - val_accuracy: 0.7855\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1332 - accuracy: 0.9549 - val_loss: 0.9715 - val_accuracy: 0.7636\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1465 - accuracy: 0.9507 - val_loss: 1.1252 - val_accuracy: 0.7754\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.1287 - accuracy: 0.9552 - val_loss: 0.9674 - val_accuracy: 0.7624\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.1430 - accuracy: 0.9512 - val_loss: 1.0438 - val_accuracy: 0.7689\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1331 - accuracy: 0.9560 - val_loss: 0.9296 - val_accuracy: 0.7896\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1020 - accuracy: 0.9651 - val_loss: 0.8537 - val_accuracy: 0.7991\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1031 - accuracy: 0.9668 - val_loss: 1.0299 - val_accuracy: 0.7742\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1074 - accuracy: 0.9663 - val_loss: 0.9971 - val_accuracy: 0.7825\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0846 - accuracy: 0.7798\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 22ms/step - loss: 1.8959 - accuracy: 0.3613 - val_loss: 1.4762 - val_accuracy: 0.4929\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.2857 - accuracy: 0.5533 - val_loss: 1.3216 - val_accuracy: 0.5485\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.0528 - accuracy: 0.6364 - val_loss: 1.1664 - val_accuracy: 0.6093\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.8986 - accuracy: 0.6885 - val_loss: 0.9713 - val_accuracy: 0.6690\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7774 - accuracy: 0.7360 - val_loss: 1.1465 - val_accuracy: 0.6052\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7101 - accuracy: 0.7630 - val_loss: 1.2910 - val_accuracy: 0.6206\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6562 - accuracy: 0.7790 - val_loss: 1.0255 - val_accuracy: 0.6625\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5939 - accuracy: 0.7968 - val_loss: 0.8623 - val_accuracy: 0.7187\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5397 - accuracy: 0.8223 - val_loss: 1.0538 - val_accuracy: 0.6838\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5072 - accuracy: 0.8270 - val_loss: 0.7049 - val_accuracy: 0.7654\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4585 - accuracy: 0.8452 - val_loss: 1.0427 - val_accuracy: 0.6838\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4349 - accuracy: 0.8590 - val_loss: 0.7349 - val_accuracy: 0.7648\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4012 - accuracy: 0.8686 - val_loss: 0.7235 - val_accuracy: 0.7636\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3888 - accuracy: 0.8641 - val_loss: 0.6527 - val_accuracy: 0.7837\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3510 - accuracy: 0.8880 - val_loss: 0.7013 - val_accuracy: 0.7736\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3273 - accuracy: 0.8927 - val_loss: 0.6496 - val_accuracy: 0.7955\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3154 - accuracy: 0.8914 - val_loss: 0.7680 - val_accuracy: 0.7571\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2840 - accuracy: 0.9069 - val_loss: 0.7474 - val_accuracy: 0.7748\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2697 - accuracy: 0.9112 - val_loss: 0.8363 - val_accuracy: 0.7447\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2565 - accuracy: 0.9158 - val_loss: 0.5728 - val_accuracy: 0.8251\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2545 - accuracy: 0.9177 - val_loss: 0.7337 - val_accuracy: 0.7618\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2205 - accuracy: 0.9260 - val_loss: 1.0114 - val_accuracy: 0.7139\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2266 - accuracy: 0.9243 - val_loss: 0.8100 - val_accuracy: 0.7600\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2110 - accuracy: 0.9292 - val_loss: 0.6350 - val_accuracy: 0.7996\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1933 - accuracy: 0.9350 - val_loss: 0.6975 - val_accuracy: 0.7866\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1771 - accuracy: 0.9410 - val_loss: 0.6353 - val_accuracy: 0.8091\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1846 - accuracy: 0.9393 - val_loss: 0.6187 - val_accuracy: 0.8150\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1713 - accuracy: 0.9437 - val_loss: 0.5968 - val_accuracy: 0.8209\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1528 - accuracy: 0.9527 - val_loss: 0.5973 - val_accuracy: 0.8132\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1665 - accuracy: 0.9437 - val_loss: 0.7822 - val_accuracy: 0.7955\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.7407 - accuracy: 0.7830\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.3, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 7s 20ms/step - loss: 1.8807 - accuracy: 0.3793 - val_loss: 1.8546 - val_accuracy: 0.3552\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.2543 - accuracy: 0.5634 - val_loss: 1.2673 - val_accuracy: 0.5845\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.0041 - accuracy: 0.6572 - val_loss: 1.2932 - val_accuracy: 0.6022\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.8489 - accuracy: 0.7086 - val_loss: 1.5259 - val_accuracy: 0.5762\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7690 - accuracy: 0.7340 - val_loss: 0.9812 - val_accuracy: 0.6761\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.6742 - accuracy: 0.7691 - val_loss: 0.9101 - val_accuracy: 0.7080\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6230 - accuracy: 0.7843 - val_loss: 0.8580 - val_accuracy: 0.7228\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5406 - accuracy: 0.8230 - val_loss: 0.6804 - val_accuracy: 0.7683\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5018 - accuracy: 0.8225 - val_loss: 0.9196 - val_accuracy: 0.7199\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4991 - accuracy: 0.8230 - val_loss: 0.9258 - val_accuracy: 0.7252\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4574 - accuracy: 0.8450 - val_loss: 0.8069 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.4184 - accuracy: 0.8536 - val_loss: 0.7229 - val_accuracy: 0.7760\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4005 - accuracy: 0.8577 - val_loss: 1.0831 - val_accuracy: 0.6980\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.3757 - accuracy: 0.8692 - val_loss: 0.7262 - val_accuracy: 0.7784\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3668 - accuracy: 0.8749 - val_loss: 0.8998 - val_accuracy: 0.7275\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3351 - accuracy: 0.8821 - val_loss: 0.9118 - val_accuracy: 0.7370\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3147 - accuracy: 0.8898 - val_loss: 0.7546 - val_accuracy: 0.7707\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3087 - accuracy: 0.8924 - val_loss: 0.6982 - val_accuracy: 0.7736\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.2934 - accuracy: 0.9009 - val_loss: 0.7400 - val_accuracy: 0.7849\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2906 - accuracy: 0.8958 - val_loss: 0.6363 - val_accuracy: 0.8109\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2875 - accuracy: 0.8989 - val_loss: 0.8101 - val_accuracy: 0.7642\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2905 - accuracy: 0.9010 - val_loss: 0.9785 - val_accuracy: 0.7600\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2775 - accuracy: 0.9035 - val_loss: 0.6646 - val_accuracy: 0.7979\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 5s 23ms/step - loss: 0.2425 - accuracy: 0.9147 - val_loss: 0.7626 - val_accuracy: 0.7961\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 5s 25ms/step - loss: 0.2458 - accuracy: 0.9122 - val_loss: 0.7911 - val_accuracy: 0.7825\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 5s 22ms/step - loss: 0.2305 - accuracy: 0.9199 - val_loss: 0.9561 - val_accuracy: 0.7559\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.2103 - accuracy: 0.9292 - val_loss: 0.7773 - val_accuracy: 0.8008\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 0.2376 - accuracy: 0.9167 - val_loss: 0.9729 - val_accuracy: 0.7612\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 0.2202 - accuracy: 0.9210 - val_loss: 0.8138 - val_accuracy: 0.8014\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.2440 - accuracy: 0.9133 - val_loss: 0.8344 - val_accuracy: 0.7855\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9031 - accuracy: 0.7851\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.3, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 7s 24ms/step - loss: 1.9349 - accuracy: 0.3446 - val_loss: 1.4645 - val_accuracy: 0.4835\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 1.3986 - accuracy: 0.4984 - val_loss: 1.3619 - val_accuracy: 0.5171\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 1.1977 - accuracy: 0.5748 - val_loss: 1.1877 - val_accuracy: 0.5869\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 1.0798 - accuracy: 0.6185 - val_loss: 0.9923 - val_accuracy: 0.6720\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.9862 - accuracy: 0.6591 - val_loss: 1.0790 - val_accuracy: 0.6300\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 0.8924 - accuracy: 0.6937 - val_loss: 1.2446 - val_accuracy: 0.5869\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.8430 - accuracy: 0.7105 - val_loss: 0.8755 - val_accuracy: 0.6968\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.7987 - accuracy: 0.7199 - val_loss: 1.0949 - val_accuracy: 0.6466\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.7500 - accuracy: 0.7349 - val_loss: 1.1137 - val_accuracy: 0.6430\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.7143 - accuracy: 0.7537 - val_loss: 0.8375 - val_accuracy: 0.7098\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.6789 - accuracy: 0.7726 - val_loss: 0.8912 - val_accuracy: 0.7222\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.6280 - accuracy: 0.7751 - val_loss: 0.8223 - val_accuracy: 0.7222\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.6100 - accuracy: 0.7908 - val_loss: 0.7568 - val_accuracy: 0.7358\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.5988 - accuracy: 0.7920 - val_loss: 0.8240 - val_accuracy: 0.7400\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.5637 - accuracy: 0.8033 - val_loss: 0.7320 - val_accuracy: 0.7796\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.5434 - accuracy: 0.8126 - val_loss: 0.7237 - val_accuracy: 0.7736\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.5018 - accuracy: 0.8262 - val_loss: 0.9115 - val_accuracy: 0.7098\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 0.4887 - accuracy: 0.8289 - val_loss: 1.0395 - val_accuracy: 0.7074\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.4552 - accuracy: 0.8415 - val_loss: 0.6322 - val_accuracy: 0.7996\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.4624 - accuracy: 0.8409 - val_loss: 0.6989 - val_accuracy: 0.7707\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.4380 - accuracy: 0.8539 - val_loss: 0.6934 - val_accuracy: 0.7707\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.4249 - accuracy: 0.8543 - val_loss: 0.7834 - val_accuracy: 0.7801\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.4007 - accuracy: 0.8587 - val_loss: 0.6972 - val_accuracy: 0.7920\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.3947 - accuracy: 0.8608 - val_loss: 0.7505 - val_accuracy: 0.7760\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.3933 - accuracy: 0.8599 - val_loss: 0.9192 - val_accuracy: 0.7293\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 4s 20ms/step - loss: 0.3682 - accuracy: 0.8735 - val_loss: 0.7130 - val_accuracy: 0.7813\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.3701 - accuracy: 0.8746 - val_loss: 0.5583 - val_accuracy: 0.8227\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.3409 - accuracy: 0.8830 - val_loss: 0.6426 - val_accuracy: 0.8203\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.3328 - accuracy: 0.8805 - val_loss: 0.7147 - val_accuracy: 0.7902\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.3345 - accuracy: 0.8846 - val_loss: 0.6174 - val_accuracy: 0.8121\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.8298\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6a11f9027cdbbffc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6a11f9027cdbbffc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "2023-12-18 19:43:25.938132: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
       "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2023-12-18 19:43:26.702147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
       "2023-12-18 19:43:27.539293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
       "Your kernel may have been built without NUMA support.\n",
       "2023-12-18 19:43:27.563768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
       "Your kernel may have been built without NUMA support.\n",
       "2023-12-18 19:43:27.564563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
       "Your kernel may have been built without NUMA support.\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
