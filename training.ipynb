{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 22:29:54.157156: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 22:29:55.232732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import librosa\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data.json\"\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 # percentage of dataset\n",
    "TEST_SPLIT = 0.1 # percentage of dataset\n",
    "\n",
    "NUM_SESSION_GROUPS = 10\n",
    "LOGDIR = \"logs/hparam_tuning/\"\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from json file\n",
    "\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "x = np.array(data[\"mfcc\"])\n",
    "y = np.array(data[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SPLIT)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=VALIDATION_SPLIT)\n",
    "\n",
    "# add an axis to input sets to match the shape CNN expects (last axis is like channel in color images)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "x_validation = x_validation[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose hyperparameters to tune\n",
    "\n",
    "# HP_CONV_LAYERS = hp.HParam(\"conv_layers\", hp.IntInterval(1, 3))\n",
    "# HP_CONV_KERNEL_SIZE = hp.HParam(\"conv_kernel_size\", hp.Discrete([3, 5]))\n",
    "# HP_POOL_SIZE = hp.HParam(\"conv_pool_size\", hp.Discrete([2, 3]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 96]))\n",
    "HP_DENSE_LAYERS = hp.HParam(\"dense_layers\", hp.IntInterval(1, 3))\n",
    "HP_DROPOUT = hp.HParam(\"dropout\", hp.RealInterval(0.2, 0.5))\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", hp.Discrete([\"adam\", \"sgd\"]))\n",
    "\n",
    "HPARAMS = [\n",
    "    # HP_CONV_LAYERS,\n",
    "    # HP_CONV_KERNEL_SIZE,\n",
    "    # HP_POOL_SIZE,\n",
    "    HP_NUM_UNITS,\n",
    "    HP_DENSE_LAYERS,\n",
    "    HP_DROPOUT,\n",
    "    HP_OPTIMIZER,\n",
    "]\n",
    "\n",
    "METRICS = [\n",
    "    hp.Metric(\n",
    "        \"epoch_accuracy\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"accuracy (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"epoch_loss\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"loss (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_accuracy\",\n",
    "        group=\"train\",\n",
    "        display_name=\"accuracy (train)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_loss\",\n",
    "        group=\"train\",\n",
    "        display_name=\"loss (train)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "#         metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams, seed):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    INPUT_SHAPE = (x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=INPUT_SHAPE))\n",
    "\n",
    "   #  conv_filters = 8\n",
    "   #  for _ in range(hparams[HP_CONV_LAYERS]):\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.Conv2D(\n",
    "   #           filters=conv_filters,\n",
    "   #          #  kernel_size=hparams[HP_CONV_KERNEL_SIZE],\n",
    "   #           kernel_size=3,\n",
    "   #           padding=\"same\",\n",
    "   #           activation=\"relu\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.MaxPooling2D(\n",
    "   #           pool_size=hparams[HP_POOL_SIZE],\n",
    "   #           strides=hparams[HP_POOL_SIZE]-1,\n",
    "   #           padding=\"same\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(tf.keras.layers.BatchNormalization())\n",
    "   #     conv_filters *= 2\n",
    "    \n",
    "    # 1st conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\\n\",\n",
    "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for _ in range(hparams[HP_DENSE_LAYERS]):\n",
    "        model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT], seed=rng.random()))\n",
    "\n",
    "    # output layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "       optimizer=hparams[HP_OPTIMIZER],\n",
    "       loss='sparse_categorical_crossentropy',\n",
    "       metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "#     fit_log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=fit_log_dir, histogram_freq=1)\n",
    "\n",
    "#     model.fit(x=x_train,\n",
    "#               y=y_train,\n",
    "#               validation_data=(x_validation, y_validation),\n",
    "#               batch_size=32,\n",
    "#               epochs=30,\n",
    "#               callbacks=[tensorboard_callback])\n",
    "    \n",
    "#     _, accuracy = model.evaluate(x_test, y_test)\n",
    "#     return accuracy\n",
    "\n",
    "\n",
    "# def run(run_dir, hparams):\n",
    "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
    "#     hp.hparams(hparams)  # record the values used in this trial\n",
    "#     accuracy = train_model(hparams)\n",
    "#     tf.summary.scalar(METRIC_ACCURACY, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(base_logdir, session_id, hparams):\n",
    "    model = create_model(hparams=hparams, seed=session_id)\n",
    "    logdir = os.path.join(base_logdir, session_id)\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logdir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "\n",
    "    hparams_callback = hp.KerasCallback(logdir, hparams)\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        validation_data=(x_validation, y_validation),\n",
    "        callbacks=[tensorboard_callback, hparams_callback]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(logdir, verbose=False):\n",
    "    rng = random.Random(0)\n",
    "\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=METRICS)\n",
    "\n",
    "    sessions_per_group = 2\n",
    "    num_sessions = NUM_SESSION_GROUPS * sessions_per_group\n",
    "    session_index = 0  # across all session groups\n",
    "    for group_index in range(NUM_SESSION_GROUPS):\n",
    "        hparams = {h: h.domain.sample_uniform(rng) for h in HPARAMS}\n",
    "        hparams_string = str(hparams)\n",
    "        for repeat_index in range(sessions_per_group):\n",
    "            session_id = str(session_index)\n",
    "            session_index += 1\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"--- Running training session %d/%d\"\n",
    "                    % (session_index, num_sessions)\n",
    "                )\n",
    "                print(hparams_string)\n",
    "                print(\"--- repeat #: %d\" % (repeat_index + 1))\n",
    "            run(\n",
    "                base_logdir=logdir,\n",
    "                session_id=session_id,\n",
    "                hparams=hparams,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to logs/hparam_tuning/\n",
      "--- Running training session 1/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.21214531345423326, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 15ms/step - loss: 1.9205 - accuracy: 0.3137 - val_loss: 1.6638 - val_accuracy: 0.4303\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.3405 - accuracy: 0.5306 - val_loss: 1.2647 - val_accuracy: 0.5502\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.0809 - accuracy: 0.6235 - val_loss: 1.2232 - val_accuracy: 0.5798\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9045 - accuracy: 0.6916 - val_loss: 1.0608 - val_accuracy: 0.6513\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7851 - accuracy: 0.7340 - val_loss: 1.1142 - val_accuracy: 0.6483\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6769 - accuracy: 0.7694 - val_loss: 0.9607 - val_accuracy: 0.6844\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6024 - accuracy: 0.7908 - val_loss: 0.8246 - val_accuracy: 0.7317\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5334 - accuracy: 0.8211 - val_loss: 0.8449 - val_accuracy: 0.7270\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4788 - accuracy: 0.8366 - val_loss: 0.7482 - val_accuracy: 0.7648\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4037 - accuracy: 0.8645 - val_loss: 0.8733 - val_accuracy: 0.7311\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3670 - accuracy: 0.8760 - val_loss: 0.7855 - val_accuracy: 0.7583\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3334 - accuracy: 0.8908 - val_loss: 0.9081 - val_accuracy: 0.7287\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2888 - accuracy: 0.9077 - val_loss: 0.7779 - val_accuracy: 0.7606\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2617 - accuracy: 0.9174 - val_loss: 0.7367 - val_accuracy: 0.7790\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2257 - accuracy: 0.9257 - val_loss: 0.8921 - val_accuracy: 0.7559\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2084 - accuracy: 0.9340 - val_loss: 1.0775 - val_accuracy: 0.7281\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1946 - accuracy: 0.9387 - val_loss: 0.8115 - val_accuracy: 0.7683\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1673 - accuracy: 0.9496 - val_loss: 0.8229 - val_accuracy: 0.7725\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1508 - accuracy: 0.9532 - val_loss: 0.8421 - val_accuracy: 0.7730\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1370 - accuracy: 0.9601 - val_loss: 0.8342 - val_accuracy: 0.7849\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1229 - accuracy: 0.9647 - val_loss: 0.7477 - val_accuracy: 0.8061\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1117 - accuracy: 0.9691 - val_loss: 0.7540 - val_accuracy: 0.7985\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0967 - accuracy: 0.9733 - val_loss: 0.8065 - val_accuracy: 0.7985\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1018 - accuracy: 0.9696 - val_loss: 0.7418 - val_accuracy: 0.8067\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0832 - accuracy: 0.9764 - val_loss: 0.9033 - val_accuracy: 0.7949\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0802 - accuracy: 0.9772 - val_loss: 0.8010 - val_accuracy: 0.8020\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0677 - accuracy: 0.9820 - val_loss: 0.8067 - val_accuracy: 0.8097\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0640 - accuracy: 0.9829 - val_loss: 0.7286 - val_accuracy: 0.8197\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0535 - accuracy: 0.9874 - val_loss: 0.9567 - val_accuracy: 0.7748\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.7693 - val_accuracy: 0.8056\n",
      "--- Running training session 2/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.21214531345423326, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 1.8781 - accuracy: 0.3323 - val_loss: 1.5780 - val_accuracy: 0.4598\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3975 - accuracy: 0.5006 - val_loss: 1.2195 - val_accuracy: 0.5680\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1612 - accuracy: 0.5903 - val_loss: 1.1280 - val_accuracy: 0.6028\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.9868 - accuracy: 0.6612 - val_loss: 1.1798 - val_accuracy: 0.6093\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8557 - accuracy: 0.7083 - val_loss: 0.9251 - val_accuracy: 0.6862\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7511 - accuracy: 0.7442 - val_loss: 0.8614 - val_accuracy: 0.7051\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6770 - accuracy: 0.7763 - val_loss: 0.8056 - val_accuracy: 0.7281\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5902 - accuracy: 0.7991 - val_loss: 0.7925 - val_accuracy: 0.7216\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5271 - accuracy: 0.8239 - val_loss: 0.9560 - val_accuracy: 0.6832\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4667 - accuracy: 0.8474 - val_loss: 0.8581 - val_accuracy: 0.7299\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4102 - accuracy: 0.8689 - val_loss: 0.8728 - val_accuracy: 0.7222\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3736 - accuracy: 0.8771 - val_loss: 0.7048 - val_accuracy: 0.7589\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3307 - accuracy: 0.8948 - val_loss: 0.8321 - val_accuracy: 0.7405\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2890 - accuracy: 0.9088 - val_loss: 0.9186 - val_accuracy: 0.7222\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2646 - accuracy: 0.9165 - val_loss: 0.7855 - val_accuracy: 0.7671\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2377 - accuracy: 0.9272 - val_loss: 0.7666 - val_accuracy: 0.7701\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2047 - accuracy: 0.9365 - val_loss: 0.7644 - val_accuracy: 0.7813\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1778 - accuracy: 0.9474 - val_loss: 0.7757 - val_accuracy: 0.7742\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1659 - accuracy: 0.9509 - val_loss: 0.7662 - val_accuracy: 0.7713\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1554 - accuracy: 0.9551 - val_loss: 0.7666 - val_accuracy: 0.7872\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1457 - accuracy: 0.9539 - val_loss: 0.6829 - val_accuracy: 0.8032\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1278 - accuracy: 0.9641 - val_loss: 0.7465 - val_accuracy: 0.7819\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1066 - accuracy: 0.9706 - val_loss: 0.7471 - val_accuracy: 0.7861\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1194 - accuracy: 0.9647 - val_loss: 0.7241 - val_accuracy: 0.8180\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0923 - accuracy: 0.9756 - val_loss: 0.7154 - val_accuracy: 0.7961\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0931 - accuracy: 0.9716 - val_loss: 0.8262 - val_accuracy: 0.7784\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0761 - accuracy: 0.9798 - val_loss: 0.6881 - val_accuracy: 0.8304\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0730 - accuracy: 0.9789 - val_loss: 0.6964 - val_accuracy: 0.8138\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0706 - accuracy: 0.9806 - val_loss: 0.8097 - val_accuracy: 0.8032\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0804 - accuracy: 0.9774 - val_loss: 0.7401 - val_accuracy: 0.8191\n",
      "--- Running training session 3/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4903399984760514, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 2.1575 - accuracy: 0.2479 - val_loss: 1.7414 - val_accuracy: 0.3966\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.6497 - accuracy: 0.4121 - val_loss: 1.3654 - val_accuracy: 0.5207\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.4102 - accuracy: 0.4883 - val_loss: 1.1922 - val_accuracy: 0.5934\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.2315 - accuracy: 0.5708 - val_loss: 1.2218 - val_accuracy: 0.5650\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0974 - accuracy: 0.6215 - val_loss: 1.0531 - val_accuracy: 0.6407\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.0010 - accuracy: 0.6594 - val_loss: 1.0626 - val_accuracy: 0.6389\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8987 - accuracy: 0.6958 - val_loss: 1.0379 - val_accuracy: 0.6554\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8181 - accuracy: 0.7256 - val_loss: 0.9930 - val_accuracy: 0.6708\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7539 - accuracy: 0.7481 - val_loss: 1.0580 - val_accuracy: 0.6649\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6924 - accuracy: 0.7670 - val_loss: 1.3848 - val_accuracy: 0.6235\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6351 - accuracy: 0.7807 - val_loss: 0.9795 - val_accuracy: 0.6862\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6032 - accuracy: 0.7958 - val_loss: 0.8241 - val_accuracy: 0.7216\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5530 - accuracy: 0.8121 - val_loss: 0.9261 - val_accuracy: 0.7157\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5050 - accuracy: 0.8310 - val_loss: 0.9424 - val_accuracy: 0.7151\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4725 - accuracy: 0.8437 - val_loss: 0.8032 - val_accuracy: 0.7470\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4292 - accuracy: 0.8564 - val_loss: 0.9089 - val_accuracy: 0.7293\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4051 - accuracy: 0.8657 - val_loss: 0.9512 - val_accuracy: 0.7270\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3750 - accuracy: 0.8771 - val_loss: 1.0089 - val_accuracy: 0.7210\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3474 - accuracy: 0.8880 - val_loss: 1.2221 - val_accuracy: 0.6980\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3068 - accuracy: 0.9038 - val_loss: 1.0428 - val_accuracy: 0.7086\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3038 - accuracy: 0.8994 - val_loss: 0.8918 - val_accuracy: 0.7411\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2814 - accuracy: 0.9069 - val_loss: 0.8303 - val_accuracy: 0.7689\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2544 - accuracy: 0.9204 - val_loss: 0.8846 - val_accuracy: 0.7654\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2346 - accuracy: 0.9220 - val_loss: 0.7572 - val_accuracy: 0.7801\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2285 - accuracy: 0.9236 - val_loss: 0.8192 - val_accuracy: 0.7784\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2151 - accuracy: 0.9303 - val_loss: 1.0031 - val_accuracy: 0.7388\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1799 - accuracy: 0.9453 - val_loss: 1.0114 - val_accuracy: 0.7506\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1815 - accuracy: 0.9409 - val_loss: 0.8297 - val_accuracy: 0.7896\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1636 - accuracy: 0.9459 - val_loss: 0.8662 - val_accuracy: 0.7707\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1662 - accuracy: 0.9450 - val_loss: 0.8253 - val_accuracy: 0.7920\n",
      "--- Running training session 4/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4903399984760514, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 2.1070 - accuracy: 0.2699 - val_loss: 1.7330 - val_accuracy: 0.3830\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.6085 - accuracy: 0.4260 - val_loss: 1.3645 - val_accuracy: 0.5266\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3663 - accuracy: 0.5163 - val_loss: 1.3074 - val_accuracy: 0.5461\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.2314 - accuracy: 0.5702 - val_loss: 1.1542 - val_accuracy: 0.6005\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.0916 - accuracy: 0.6316 - val_loss: 1.1104 - val_accuracy: 0.6105\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.9984 - accuracy: 0.6627 - val_loss: 0.9875 - val_accuracy: 0.6554\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.9132 - accuracy: 0.6918 - val_loss: 1.0326 - val_accuracy: 0.6483\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8104 - accuracy: 0.7287 - val_loss: 1.0282 - val_accuracy: 0.6554\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.7638 - accuracy: 0.7368 - val_loss: 0.9478 - val_accuracy: 0.6856\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.7114 - accuracy: 0.7559 - val_loss: 0.9422 - val_accuracy: 0.6968\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6566 - accuracy: 0.7880 - val_loss: 1.0212 - val_accuracy: 0.6690\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5935 - accuracy: 0.8014 - val_loss: 0.7613 - val_accuracy: 0.7376\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5623 - accuracy: 0.8118 - val_loss: 0.7783 - val_accuracy: 0.7400\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4983 - accuracy: 0.8308 - val_loss: 0.7893 - val_accuracy: 0.7411\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4797 - accuracy: 0.8381 - val_loss: 0.6935 - val_accuracy: 0.7825\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4515 - accuracy: 0.8543 - val_loss: 0.7265 - val_accuracy: 0.7660\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4153 - accuracy: 0.8618 - val_loss: 0.7288 - val_accuracy: 0.7801\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3685 - accuracy: 0.8802 - val_loss: 0.6914 - val_accuracy: 0.7825\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3460 - accuracy: 0.8889 - val_loss: 0.6559 - val_accuracy: 0.7955\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3374 - accuracy: 0.8890 - val_loss: 0.9146 - val_accuracy: 0.7382\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3038 - accuracy: 0.9000 - val_loss: 0.7679 - val_accuracy: 0.7600\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2825 - accuracy: 0.9087 - val_loss: 0.8022 - val_accuracy: 0.7707\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2724 - accuracy: 0.9131 - val_loss: 0.8578 - val_accuracy: 0.7730\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2575 - accuracy: 0.9167 - val_loss: 1.2247 - val_accuracy: 0.6992\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2314 - accuracy: 0.9270 - val_loss: 0.9933 - val_accuracy: 0.7636\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2229 - accuracy: 0.9266 - val_loss: 0.9827 - val_accuracy: 0.7459\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2035 - accuracy: 0.9400 - val_loss: 0.8003 - val_accuracy: 0.7819\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1979 - accuracy: 0.9374 - val_loss: 0.8856 - val_accuracy: 0.7671\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1770 - accuracy: 0.9422 - val_loss: 0.7969 - val_accuracy: 0.7872\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1668 - accuracy: 0.9464 - val_loss: 0.7742 - val_accuracy: 0.7849\n",
      "--- Running training session 5/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3514060567452171, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 1.9948 - accuracy: 0.3478 - val_loss: 1.5415 - val_accuracy: 0.4586\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.3388 - accuracy: 0.5278 - val_loss: 1.1202 - val_accuracy: 0.5987\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.1071 - accuracy: 0.6129 - val_loss: 1.1107 - val_accuracy: 0.6247\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.9669 - accuracy: 0.6585 - val_loss: 1.0317 - val_accuracy: 0.6466\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8534 - accuracy: 0.7024 - val_loss: 0.8895 - val_accuracy: 0.6927\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7579 - accuracy: 0.7330 - val_loss: 0.8737 - val_accuracy: 0.7074\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6872 - accuracy: 0.7670 - val_loss: 0.8516 - val_accuracy: 0.7074\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6219 - accuracy: 0.7874 - val_loss: 0.8918 - val_accuracy: 0.7074\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5739 - accuracy: 0.8073 - val_loss: 0.7821 - val_accuracy: 0.7364\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5267 - accuracy: 0.8193 - val_loss: 0.7396 - val_accuracy: 0.7600\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4889 - accuracy: 0.8330 - val_loss: 0.8284 - val_accuracy: 0.7429\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4479 - accuracy: 0.8440 - val_loss: 0.6755 - val_accuracy: 0.7796\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4194 - accuracy: 0.8568 - val_loss: 0.7323 - val_accuracy: 0.7636\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3779 - accuracy: 0.8689 - val_loss: 0.7573 - val_accuracy: 0.7695\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3502 - accuracy: 0.8808 - val_loss: 0.6480 - val_accuracy: 0.7914\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3306 - accuracy: 0.8886 - val_loss: 0.6252 - val_accuracy: 0.8002\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3039 - accuracy: 0.9004 - val_loss: 0.6220 - val_accuracy: 0.7985\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2788 - accuracy: 0.9057 - val_loss: 0.7385 - val_accuracy: 0.7719\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2661 - accuracy: 0.9088 - val_loss: 0.6663 - val_accuracy: 0.7813\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2527 - accuracy: 0.9131 - val_loss: 0.6893 - val_accuracy: 0.7908\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2444 - accuracy: 0.9173 - val_loss: 0.5976 - val_accuracy: 0.8044\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2147 - accuracy: 0.9310 - val_loss: 0.7030 - val_accuracy: 0.7760\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2028 - accuracy: 0.9337 - val_loss: 0.6925 - val_accuracy: 0.8056\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2021 - accuracy: 0.9326 - val_loss: 0.6391 - val_accuracy: 0.8162\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1804 - accuracy: 0.9402 - val_loss: 0.5930 - val_accuracy: 0.8233\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1689 - accuracy: 0.9446 - val_loss: 0.7036 - val_accuracy: 0.7843\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1589 - accuracy: 0.9499 - val_loss: 0.6386 - val_accuracy: 0.8056\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1505 - accuracy: 0.9533 - val_loss: 0.7611 - val_accuracy: 0.7784\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1461 - accuracy: 0.9532 - val_loss: 0.6491 - val_accuracy: 0.8103\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1394 - accuracy: 0.9529 - val_loss: 0.5911 - val_accuracy: 0.8209\n",
      "--- Running training session 6/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3514060567452171, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 1.9530 - accuracy: 0.3521 - val_loss: 1.9866 - val_accuracy: 0.3517\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3078 - accuracy: 0.5479 - val_loss: 1.4108 - val_accuracy: 0.5124\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0804 - accuracy: 0.6206 - val_loss: 1.0478 - val_accuracy: 0.6318\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9366 - accuracy: 0.6788 - val_loss: 1.0561 - val_accuracy: 0.6229\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8209 - accuracy: 0.7163 - val_loss: 0.9091 - val_accuracy: 0.6820\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7331 - accuracy: 0.7491 - val_loss: 1.2747 - val_accuracy: 0.6017\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6546 - accuracy: 0.7778 - val_loss: 0.7593 - val_accuracy: 0.7388\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5959 - accuracy: 0.7976 - val_loss: 0.7614 - val_accuracy: 0.7423\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5446 - accuracy: 0.8128 - val_loss: 0.6987 - val_accuracy: 0.7636\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4992 - accuracy: 0.8295 - val_loss: 0.7637 - val_accuracy: 0.7364\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4465 - accuracy: 0.8497 - val_loss: 0.6923 - val_accuracy: 0.7671\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4089 - accuracy: 0.8616 - val_loss: 0.8681 - val_accuracy: 0.7222\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3886 - accuracy: 0.8661 - val_loss: 0.7356 - val_accuracy: 0.7689\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3593 - accuracy: 0.8729 - val_loss: 0.7752 - val_accuracy: 0.7470\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3301 - accuracy: 0.8890 - val_loss: 0.6919 - val_accuracy: 0.7790\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3047 - accuracy: 0.8995 - val_loss: 0.6204 - val_accuracy: 0.8020\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2812 - accuracy: 0.9059 - val_loss: 0.8518 - val_accuracy: 0.7465\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2658 - accuracy: 0.9116 - val_loss: 0.7035 - val_accuracy: 0.7926\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2476 - accuracy: 0.9168 - val_loss: 0.6631 - val_accuracy: 0.7961\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2280 - accuracy: 0.9288 - val_loss: 0.6044 - val_accuracy: 0.8156\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2247 - accuracy: 0.9263 - val_loss: 0.6955 - val_accuracy: 0.7813\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2015 - accuracy: 0.9344 - val_loss: 0.6850 - val_accuracy: 0.7979\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1916 - accuracy: 0.9387 - val_loss: 0.6830 - val_accuracy: 0.8097\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1839 - accuracy: 0.9403 - val_loss: 0.6301 - val_accuracy: 0.8056\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1711 - accuracy: 0.9456 - val_loss: 0.5747 - val_accuracy: 0.8233\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1567 - accuracy: 0.9514 - val_loss: 0.5676 - val_accuracy: 0.8257\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1517 - accuracy: 0.9533 - val_loss: 0.6649 - val_accuracy: 0.8067\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1377 - accuracy: 0.9595 - val_loss: 0.7533 - val_accuracy: 0.7813\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1393 - accuracy: 0.9583 - val_loss: 0.7390 - val_accuracy: 0.7931\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1274 - accuracy: 0.9597 - val_loss: 0.6725 - val_accuracy: 0.8073\n",
      "--- Running training session 7/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3855106990025995, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 15ms/step - loss: 2.0814 - accuracy: 0.2951 - val_loss: 1.7180 - val_accuracy: 0.3954\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.5739 - accuracy: 0.4393 - val_loss: 1.4693 - val_accuracy: 0.4722\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3654 - accuracy: 0.5199 - val_loss: 1.4541 - val_accuracy: 0.4935\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.2342 - accuracy: 0.5635 - val_loss: 1.0918 - val_accuracy: 0.6288\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1433 - accuracy: 0.5993 - val_loss: 1.0492 - val_accuracy: 0.6324\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0368 - accuracy: 0.6384 - val_loss: 1.0768 - val_accuracy: 0.6342\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.9547 - accuracy: 0.6680 - val_loss: 1.0178 - val_accuracy: 0.6543\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9043 - accuracy: 0.6878 - val_loss: 1.0908 - val_accuracy: 0.6294\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8506 - accuracy: 0.7023 - val_loss: 1.2993 - val_accuracy: 0.5851\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8017 - accuracy: 0.7216 - val_loss: 1.2745 - val_accuracy: 0.5957\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7394 - accuracy: 0.7385 - val_loss: 1.0067 - val_accuracy: 0.6726\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7191 - accuracy: 0.7516 - val_loss: 0.8455 - val_accuracy: 0.7163\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6720 - accuracy: 0.7614 - val_loss: 1.1805 - val_accuracy: 0.6152\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6291 - accuracy: 0.7840 - val_loss: 0.9590 - val_accuracy: 0.6743\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6103 - accuracy: 0.7853 - val_loss: 0.9425 - val_accuracy: 0.6992\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5791 - accuracy: 0.7936 - val_loss: 0.8824 - val_accuracy: 0.7063\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5452 - accuracy: 0.8134 - val_loss: 0.7888 - val_accuracy: 0.7476\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5159 - accuracy: 0.8197 - val_loss: 0.7994 - val_accuracy: 0.7352\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5182 - accuracy: 0.8212 - val_loss: 1.0311 - val_accuracy: 0.6832\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4892 - accuracy: 0.8236 - val_loss: 1.0076 - val_accuracy: 0.6956\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4672 - accuracy: 0.8376 - val_loss: 0.6914 - val_accuracy: 0.7843\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4536 - accuracy: 0.8366 - val_loss: 0.7435 - val_accuracy: 0.7642\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4352 - accuracy: 0.8469 - val_loss: 0.6403 - val_accuracy: 0.7967\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4315 - accuracy: 0.8497 - val_loss: 0.7303 - val_accuracy: 0.7642\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3988 - accuracy: 0.8601 - val_loss: 0.6627 - val_accuracy: 0.7949\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3887 - accuracy: 0.8602 - val_loss: 0.7702 - val_accuracy: 0.7778\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3754 - accuracy: 0.8645 - val_loss: 0.6766 - val_accuracy: 0.8091\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3719 - accuracy: 0.8650 - val_loss: 0.7620 - val_accuracy: 0.7772\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3584 - accuracy: 0.8765 - val_loss: 0.6647 - val_accuracy: 0.7926\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3203 - accuracy: 0.8876 - val_loss: 0.6657 - val_accuracy: 0.8150\n",
      "--- Running training session 8/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3855106990025995, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 2.1062 - accuracy: 0.2928 - val_loss: 1.6917 - val_accuracy: 0.3948\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.5580 - accuracy: 0.4486 - val_loss: 1.2986 - val_accuracy: 0.5296\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.3525 - accuracy: 0.5148 - val_loss: 1.2219 - val_accuracy: 0.5774\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.2114 - accuracy: 0.5687 - val_loss: 1.2428 - val_accuracy: 0.5745\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.1128 - accuracy: 0.6085 - val_loss: 1.0028 - val_accuracy: 0.6377\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0049 - accuracy: 0.6452 - val_loss: 1.0715 - val_accuracy: 0.6377\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9404 - accuracy: 0.6656 - val_loss: 0.9265 - val_accuracy: 0.6732\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8778 - accuracy: 0.6931 - val_loss: 0.8535 - val_accuracy: 0.7074\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8388 - accuracy: 0.7035 - val_loss: 0.8313 - val_accuracy: 0.7175\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7916 - accuracy: 0.7237 - val_loss: 0.9300 - val_accuracy: 0.6891\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7490 - accuracy: 0.7379 - val_loss: 0.7734 - val_accuracy: 0.7364\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7132 - accuracy: 0.7398 - val_loss: 0.7596 - val_accuracy: 0.7465\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6704 - accuracy: 0.7660 - val_loss: 0.7229 - val_accuracy: 0.7547\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6377 - accuracy: 0.7745 - val_loss: 0.7158 - val_accuracy: 0.7494\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6176 - accuracy: 0.7847 - val_loss: 0.8365 - val_accuracy: 0.7323\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5916 - accuracy: 0.7949 - val_loss: 0.7424 - val_accuracy: 0.7506\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5569 - accuracy: 0.8025 - val_loss: 0.7207 - val_accuracy: 0.7695\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5256 - accuracy: 0.8140 - val_loss: 0.6557 - val_accuracy: 0.7843\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5019 - accuracy: 0.8248 - val_loss: 0.6772 - val_accuracy: 0.7825\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4820 - accuracy: 0.8305 - val_loss: 0.7307 - val_accuracy: 0.7665\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4778 - accuracy: 0.8279 - val_loss: 0.7525 - val_accuracy: 0.7630\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4369 - accuracy: 0.8469 - val_loss: 0.7885 - val_accuracy: 0.7470\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4353 - accuracy: 0.8452 - val_loss: 0.8279 - val_accuracy: 0.7411\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4243 - accuracy: 0.8505 - val_loss: 0.6396 - val_accuracy: 0.8008\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3824 - accuracy: 0.8642 - val_loss: 0.7427 - val_accuracy: 0.7760\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3876 - accuracy: 0.8658 - val_loss: 0.6807 - val_accuracy: 0.7902\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3698 - accuracy: 0.8698 - val_loss: 0.6395 - val_accuracy: 0.8038\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3484 - accuracy: 0.8822 - val_loss: 0.7075 - val_accuracy: 0.7849\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3341 - accuracy: 0.8845 - val_loss: 0.7362 - val_accuracy: 0.7760\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3302 - accuracy: 0.8833 - val_loss: 0.7851 - val_accuracy: 0.7825\n",
      "--- Running training session 9/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4430651707989769, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 22:42:53.826752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 6s 15ms/step - loss: 1.7006 - accuracy: 0.3978 - val_loss: 1.6409 - val_accuracy: 0.4527\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.0914 - accuracy: 0.6401 - val_loss: 1.1145 - val_accuracy: 0.6348\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.7856 - accuracy: 0.7363 - val_loss: 0.9014 - val_accuracy: 0.7258\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6120 - accuracy: 0.8011 - val_loss: 0.8186 - val_accuracy: 0.7630\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4445 - accuracy: 0.8599 - val_loss: 0.9683 - val_accuracy: 0.7411\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3520 - accuracy: 0.8890 - val_loss: 0.9209 - val_accuracy: 0.7624\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2966 - accuracy: 0.9093 - val_loss: 0.8883 - val_accuracy: 0.7790\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2364 - accuracy: 0.9280 - val_loss: 1.0048 - val_accuracy: 0.7671\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1940 - accuracy: 0.9384 - val_loss: 1.3916 - val_accuracy: 0.7417\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1707 - accuracy: 0.9459 - val_loss: 1.0111 - val_accuracy: 0.7801\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1712 - accuracy: 0.9477 - val_loss: 1.2700 - val_accuracy: 0.7506\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1575 - accuracy: 0.9498 - val_loss: 0.9959 - val_accuracy: 0.7831\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1055 - accuracy: 0.9684 - val_loss: 1.4025 - val_accuracy: 0.7364\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1490 - accuracy: 0.9542 - val_loss: 1.5858 - val_accuracy: 0.7069\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1048 - accuracy: 0.9681 - val_loss: 1.1892 - val_accuracy: 0.7730\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0924 - accuracy: 0.9733 - val_loss: 1.3317 - val_accuracy: 0.7618\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1218 - accuracy: 0.9637 - val_loss: 1.6982 - val_accuracy: 0.7376\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1246 - accuracy: 0.9651 - val_loss: 1.4555 - val_accuracy: 0.7435\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0743 - accuracy: 0.9778 - val_loss: 1.0955 - val_accuracy: 0.7654\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0681 - accuracy: 0.9801 - val_loss: 1.2323 - val_accuracy: 0.7967\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1022 - accuracy: 0.9724 - val_loss: 1.2983 - val_accuracy: 0.7654\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 1.1098 - val_accuracy: 0.7991\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 1.3392 - val_accuracy: 0.7571\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0832 - accuracy: 0.9801 - val_loss: 2.2834 - val_accuracy: 0.6868\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 1.2167 - val_accuracy: 0.8109\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0562 - accuracy: 0.9848 - val_loss: 1.4379 - val_accuracy: 0.7589\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.0684 - accuracy: 0.9790 - val_loss: 1.7171 - val_accuracy: 0.7394\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 1.4438 - val_accuracy: 0.7742\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 17ms/step - loss: 0.0692 - accuracy: 0.9808 - val_loss: 1.5140 - val_accuracy: 0.7606\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 2.6023 - val_accuracy: 0.7098\n",
      "--- Running training session 10/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4430651707989769, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 15ms/step - loss: 1.6817 - accuracy: 0.4133 - val_loss: 1.7055 - val_accuracy: 0.4504\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.1444 - accuracy: 0.6198 - val_loss: 0.9634 - val_accuracy: 0.6696\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.8475 - accuracy: 0.7259 - val_loss: 1.0890 - val_accuracy: 0.6667\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.6552 - accuracy: 0.7853 - val_loss: 0.8140 - val_accuracy: 0.7335\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.5121 - accuracy: 0.8341 - val_loss: 1.0152 - val_accuracy: 0.7039\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3986 - accuracy: 0.8728 - val_loss: 1.3011 - val_accuracy: 0.6879\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3254 - accuracy: 0.8969 - val_loss: 1.3489 - val_accuracy: 0.6939\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2932 - accuracy: 0.9081 - val_loss: 1.1660 - val_accuracy: 0.7222\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2159 - accuracy: 0.9304 - val_loss: 0.9931 - val_accuracy: 0.7618\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2169 - accuracy: 0.9294 - val_loss: 1.4195 - val_accuracy: 0.7275\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1551 - accuracy: 0.9505 - val_loss: 1.4096 - val_accuracy: 0.7524\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1758 - accuracy: 0.9455 - val_loss: 1.1842 - val_accuracy: 0.7624\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1352 - accuracy: 0.9600 - val_loss: 1.1152 - val_accuracy: 0.7630\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1399 - accuracy: 0.9586 - val_loss: 1.2838 - val_accuracy: 0.7689\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1379 - accuracy: 0.9608 - val_loss: 1.5500 - val_accuracy: 0.7305\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0976 - accuracy: 0.9690 - val_loss: 1.6836 - val_accuracy: 0.7370\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1157 - accuracy: 0.9656 - val_loss: 1.3914 - val_accuracy: 0.7400\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1019 - accuracy: 0.9713 - val_loss: 1.6271 - val_accuracy: 0.7216\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0774 - accuracy: 0.9765 - val_loss: 1.2948 - val_accuracy: 0.7742\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 4s 19ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 1.4277 - val_accuracy: 0.7654\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 4s 21ms/step - loss: 0.0760 - accuracy: 0.9809 - val_loss: 1.6417 - val_accuracy: 0.7246\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 1.5885 - val_accuracy: 0.7624\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0947 - accuracy: 0.9724 - val_loss: 1.2011 - val_accuracy: 0.7884\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0854 - accuracy: 0.9755 - val_loss: 1.6359 - val_accuracy: 0.7329\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 1.4598 - val_accuracy: 0.7695\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 1.9363 - val_accuracy: 0.7376\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0856 - accuracy: 0.9749 - val_loss: 1.4529 - val_accuracy: 0.7730\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0716 - accuracy: 0.9811 - val_loss: 1.5784 - val_accuracy: 0.7459\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0482 - accuracy: 0.9867 - val_loss: 1.3873 - val_accuracy: 0.7872\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 1.5528 - val_accuracy: 0.7612\n",
      "--- Running training session 11/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.41894952447803857, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 5s 17ms/step - loss: 2.0720 - accuracy: 0.3206 - val_loss: 1.6717 - val_accuracy: 0.4066\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 1.4327 - accuracy: 0.4951 - val_loss: 1.2245 - val_accuracy: 0.5597\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 17ms/step - loss: 1.2100 - accuracy: 0.5725 - val_loss: 1.2852 - val_accuracy: 0.5609\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 17ms/step - loss: 1.0410 - accuracy: 0.6350 - val_loss: 0.9513 - val_accuracy: 0.6785\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9446 - accuracy: 0.6727 - val_loss: 0.9062 - val_accuracy: 0.6915\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.8479 - accuracy: 0.7107 - val_loss: 0.9087 - val_accuracy: 0.6885\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7802 - accuracy: 0.7361 - val_loss: 0.8814 - val_accuracy: 0.6868\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.7241 - accuracy: 0.7496 - val_loss: 0.8662 - val_accuracy: 0.7039\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6676 - accuracy: 0.7699 - val_loss: 0.7305 - val_accuracy: 0.7453\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.6200 - accuracy: 0.7852 - val_loss: 0.8484 - val_accuracy: 0.7080\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.5809 - accuracy: 0.8051 - val_loss: 0.6722 - val_accuracy: 0.7612\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5384 - accuracy: 0.8172 - val_loss: 0.7339 - val_accuracy: 0.7630\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4875 - accuracy: 0.8347 - val_loss: 0.7408 - val_accuracy: 0.7565\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4779 - accuracy: 0.8332 - val_loss: 0.6332 - val_accuracy: 0.7937\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4492 - accuracy: 0.8413 - val_loss: 0.7199 - val_accuracy: 0.7476\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4104 - accuracy: 0.8556 - val_loss: 0.6383 - val_accuracy: 0.7878\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4070 - accuracy: 0.8621 - val_loss: 0.5915 - val_accuracy: 0.8132\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3857 - accuracy: 0.8654 - val_loss: 0.6334 - val_accuracy: 0.7866\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3518 - accuracy: 0.8837 - val_loss: 0.5925 - val_accuracy: 0.8079\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3333 - accuracy: 0.8861 - val_loss: 0.5893 - val_accuracy: 0.8115\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3124 - accuracy: 0.8935 - val_loss: 0.6198 - val_accuracy: 0.8067\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2904 - accuracy: 0.9023 - val_loss: 0.6092 - val_accuracy: 0.8085\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2960 - accuracy: 0.8979 - val_loss: 0.6732 - val_accuracy: 0.7973\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2641 - accuracy: 0.9097 - val_loss: 0.6186 - val_accuracy: 0.8126\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2473 - accuracy: 0.9193 - val_loss: 0.6755 - val_accuracy: 0.8067\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2464 - accuracy: 0.9198 - val_loss: 0.7712 - val_accuracy: 0.7642\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2401 - accuracy: 0.9187 - val_loss: 0.5745 - val_accuracy: 0.8156\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2253 - accuracy: 0.9211 - val_loss: 0.6133 - val_accuracy: 0.8268\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2152 - accuracy: 0.9232 - val_loss: 0.6149 - val_accuracy: 0.8156\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2115 - accuracy: 0.9279 - val_loss: 0.6167 - val_accuracy: 0.8115\n",
      "--- Running training session 12/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.41894952447803857, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 5s 19ms/step - loss: 2.0435 - accuracy: 0.3236 - val_loss: 1.7546 - val_accuracy: 0.3635\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.4580 - accuracy: 0.4922 - val_loss: 1.5004 - val_accuracy: 0.4864\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.2475 - accuracy: 0.5652 - val_loss: 1.4094 - val_accuracy: 0.5496\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.1069 - accuracy: 0.6127 - val_loss: 1.6428 - val_accuracy: 0.5012\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9982 - accuracy: 0.6523 - val_loss: 1.1283 - val_accuracy: 0.6235\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.8808 - accuracy: 0.7009 - val_loss: 1.0300 - val_accuracy: 0.6537\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.8177 - accuracy: 0.7182 - val_loss: 1.0724 - val_accuracy: 0.6413\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.7511 - accuracy: 0.7429 - val_loss: 1.3750 - val_accuracy: 0.5987\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.7012 - accuracy: 0.7592 - val_loss: 0.9506 - val_accuracy: 0.6992\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.6623 - accuracy: 0.7723 - val_loss: 1.0317 - val_accuracy: 0.6785\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.6117 - accuracy: 0.7995 - val_loss: 0.8277 - val_accuracy: 0.7370\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5747 - accuracy: 0.8076 - val_loss: 0.7762 - val_accuracy: 0.7547\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.5360 - accuracy: 0.8180 - val_loss: 0.7998 - val_accuracy: 0.7535\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5055 - accuracy: 0.8299 - val_loss: 0.9168 - val_accuracy: 0.7181\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4746 - accuracy: 0.8375 - val_loss: 0.8730 - val_accuracy: 0.7400\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4589 - accuracy: 0.8378 - val_loss: 0.7980 - val_accuracy: 0.7459\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.4215 - accuracy: 0.8589 - val_loss: 0.7593 - val_accuracy: 0.7683\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.4123 - accuracy: 0.8583 - val_loss: 0.9789 - val_accuracy: 0.7045\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3847 - accuracy: 0.8641 - val_loss: 0.7573 - val_accuracy: 0.7600\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3691 - accuracy: 0.8717 - val_loss: 0.7617 - val_accuracy: 0.7677\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3414 - accuracy: 0.8833 - val_loss: 0.6809 - val_accuracy: 0.7961\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3277 - accuracy: 0.8898 - val_loss: 0.7844 - val_accuracy: 0.7748\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3188 - accuracy: 0.8930 - val_loss: 0.7620 - val_accuracy: 0.7695\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3029 - accuracy: 0.8983 - val_loss: 0.8258 - val_accuracy: 0.7612\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2874 - accuracy: 0.9046 - val_loss: 0.7308 - val_accuracy: 0.7796\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2751 - accuracy: 0.9068 - val_loss: 0.7000 - val_accuracy: 0.8008\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2623 - accuracy: 0.9125 - val_loss: 0.7954 - val_accuracy: 0.7719\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2617 - accuracy: 0.9108 - val_loss: 0.7768 - val_accuracy: 0.7908\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2343 - accuracy: 0.9176 - val_loss: 0.7567 - val_accuracy: 0.7926\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.2306 - accuracy: 0.9227 - val_loss: 0.7155 - val_accuracy: 0.7996\n",
      "--- Running training session 13/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.23021036242050974, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 19ms/step - loss: 2.0507 - accuracy: 0.2621 - val_loss: 1.8053 - val_accuracy: 0.4066\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 1.5170 - accuracy: 0.4607 - val_loss: 1.3820 - val_accuracy: 0.5065\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 1.2351 - accuracy: 0.5689 - val_loss: 1.1653 - val_accuracy: 0.5904\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 1.0469 - accuracy: 0.6345 - val_loss: 1.2534 - val_accuracy: 0.5691\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.9023 - accuracy: 0.6899 - val_loss: 1.0711 - val_accuracy: 0.6176\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.7747 - accuracy: 0.7339 - val_loss: 1.1693 - val_accuracy: 0.6229\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.6708 - accuracy: 0.7739 - val_loss: 0.9738 - val_accuracy: 0.6761\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5837 - accuracy: 0.8064 - val_loss: 1.0117 - val_accuracy: 0.6696\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.5338 - accuracy: 0.8184 - val_loss: 0.8471 - val_accuracy: 0.7222\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.4552 - accuracy: 0.8456 - val_loss: 0.8559 - val_accuracy: 0.7246\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 4s 17ms/step - loss: 0.4043 - accuracy: 0.8673 - val_loss: 0.8981 - val_accuracy: 0.7222\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.3556 - accuracy: 0.8822 - val_loss: 0.7347 - val_accuracy: 0.7642\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.3094 - accuracy: 0.9019 - val_loss: 0.8985 - val_accuracy: 0.7281\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 4s 18ms/step - loss: 0.2762 - accuracy: 0.9112 - val_loss: 0.7484 - val_accuracy: 0.7730\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2448 - accuracy: 0.9211 - val_loss: 0.8067 - val_accuracy: 0.7654\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.2040 - accuracy: 0.9390 - val_loss: 0.7968 - val_accuracy: 0.7618\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.1920 - accuracy: 0.9391 - val_loss: 0.8925 - val_accuracy: 0.7435\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1689 - accuracy: 0.9502 - val_loss: 0.7987 - val_accuracy: 0.7760\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1449 - accuracy: 0.9567 - val_loss: 0.7409 - val_accuracy: 0.7967\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1250 - accuracy: 0.9639 - val_loss: 0.8462 - val_accuracy: 0.7719\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1131 - accuracy: 0.9665 - val_loss: 0.8483 - val_accuracy: 0.7819\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1045 - accuracy: 0.9690 - val_loss: 0.8077 - val_accuracy: 0.8044\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0913 - accuracy: 0.9761 - val_loss: 0.8427 - val_accuracy: 0.7943\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0836 - accuracy: 0.9741 - val_loss: 0.8310 - val_accuracy: 0.7931\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 1.1851 - val_accuracy: 0.7459\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0707 - accuracy: 0.9793 - val_loss: 0.8567 - val_accuracy: 0.7961\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0584 - accuracy: 0.9858 - val_loss: 0.8029 - val_accuracy: 0.8097\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0567 - accuracy: 0.9833 - val_loss: 1.0296 - val_accuracy: 0.7926\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: 1.1179 - val_accuracy: 0.7535\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0451 - accuracy: 0.9879 - val_loss: 0.9490 - val_accuracy: 0.8020\n",
      "--- Running training session 14/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.23021036242050974, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 5s 16ms/step - loss: 2.0178 - accuracy: 0.2621 - val_loss: 1.7339 - val_accuracy: 0.4309\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.5369 - accuracy: 0.4557 - val_loss: 1.3837 - val_accuracy: 0.5148\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.2817 - accuracy: 0.5539 - val_loss: 1.1436 - val_accuracy: 0.6017\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.1041 - accuracy: 0.6161 - val_loss: 1.0800 - val_accuracy: 0.6336\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.9743 - accuracy: 0.6741 - val_loss: 1.0696 - val_accuracy: 0.6283\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.8549 - accuracy: 0.7076 - val_loss: 1.1375 - val_accuracy: 0.6294\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.7429 - accuracy: 0.7481 - val_loss: 1.0681 - val_accuracy: 0.6543\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.6569 - accuracy: 0.7797 - val_loss: 0.9993 - val_accuracy: 0.6773\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5803 - accuracy: 0.8124 - val_loss: 0.9748 - val_accuracy: 0.6921\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.5075 - accuracy: 0.8320 - val_loss: 0.8502 - val_accuracy: 0.7252\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 16ms/step - loss: 0.4450 - accuracy: 0.8548 - val_loss: 0.8934 - val_accuracy: 0.7311\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3911 - accuracy: 0.8706 - val_loss: 0.9392 - val_accuracy: 0.7216\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.3414 - accuracy: 0.8880 - val_loss: 0.7728 - val_accuracy: 0.7713\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2993 - accuracy: 0.9012 - val_loss: 0.8138 - val_accuracy: 0.7524\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2544 - accuracy: 0.9178 - val_loss: 0.9028 - val_accuracy: 0.7595\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2307 - accuracy: 0.9310 - val_loss: 0.7801 - val_accuracy: 0.7778\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1996 - accuracy: 0.9390 - val_loss: 0.7871 - val_accuracy: 0.7801\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1845 - accuracy: 0.9424 - val_loss: 0.9893 - val_accuracy: 0.7388\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1575 - accuracy: 0.9521 - val_loss: 0.8824 - val_accuracy: 0.7748\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.1362 - accuracy: 0.9604 - val_loss: 0.8542 - val_accuracy: 0.7760\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1248 - accuracy: 0.9642 - val_loss: 0.8866 - val_accuracy: 0.7796\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.1096 - accuracy: 0.9691 - val_loss: 0.8733 - val_accuracy: 0.7695\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0944 - accuracy: 0.9713 - val_loss: 0.8147 - val_accuracy: 0.8073\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0796 - accuracy: 0.9774 - val_loss: 0.9620 - val_accuracy: 0.7831\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0803 - accuracy: 0.9758 - val_loss: 0.9204 - val_accuracy: 0.7861\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0667 - accuracy: 0.9814 - val_loss: 0.8749 - val_accuracy: 0.7872\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0610 - accuracy: 0.9815 - val_loss: 1.1064 - val_accuracy: 0.7654\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0579 - accuracy: 0.9840 - val_loss: 0.9188 - val_accuracy: 0.7931\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 15ms/step - loss: 0.0622 - accuracy: 0.9824 - val_loss: 1.2357 - val_accuracy: 0.7352\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0557 - accuracy: 0.9832 - val_loss: 0.8998 - val_accuracy: 0.7890\n",
      "--- Running training session 15/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.39212702046262704, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "np.random.seed(0)\n",
    "logdir = LOGDIR\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(f\"Saving output to {logdir}\")\n",
    "run_all(logdir=logdir, verbose=True)\n",
    "print(f\"Done. Output saved to {logdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fd12ed56f5e1435\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fd12ed56f5e1435\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
