{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 23:16:55.004323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 23:16:56.097641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data.json\"\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 # percentage of dataset\n",
    "TEST_SPLIT = 0.1 # percentage of dataset\n",
    "\n",
    "NUM_SESSION_GROUPS = 10\n",
    "LOGDIR = \"logs/hparam_tuning/\"\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from json file\n",
    "\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "x = np.array(data[\"mfcc\"])\n",
    "y = np.array(data[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SPLIT)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=VALIDATION_SPLIT)\n",
    "\n",
    "# add an axis to input sets to match the shape CNN expects (last axis is like channel in color images)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "x_validation = x_validation[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose hyperparameters to tune\n",
    "\n",
    "# HP_CONV_LAYERS = hp.HParam(\"conv_layers\", hp.IntInterval(1, 3))\n",
    "# HP_CONV_KERNEL_SIZE = hp.HParam(\"conv_kernel_size\", hp.Discrete([3, 5]))\n",
    "# HP_POOL_SIZE = hp.HParam(\"conv_pool_size\", hp.Discrete([2, 3]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 96]))\n",
    "HP_DENSE_LAYERS = hp.HParam(\"dense_layers\", hp.IntInterval(1, 3))\n",
    "HP_DROPOUT = hp.HParam(\"dropout\", hp.RealInterval(0.2, 0.5))\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", hp.Discrete([\"adam\", \"sgd\"]))\n",
    "\n",
    "HPARAMS = [\n",
    "    # HP_CONV_LAYERS,\n",
    "    # HP_CONV_KERNEL_SIZE,\n",
    "    # HP_POOL_SIZE,\n",
    "    HP_NUM_UNITS,\n",
    "    HP_DENSE_LAYERS,\n",
    "    HP_DROPOUT,\n",
    "    HP_OPTIMIZER,\n",
    "]\n",
    "\n",
    "METRICS = [\n",
    "    hp.Metric(\n",
    "        \"epoch_accuracy\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"accuracy (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"epoch_loss\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"loss (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_accuracy\",\n",
    "        group=\"train\",\n",
    "        display_name=\"accuracy (train)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_loss\",\n",
    "        group=\"train\",\n",
    "        display_name=\"loss (train)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#     hp.hparams_config(\n",
    "#         hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "#         metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams, seed):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    INPUT_SHAPE = (x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=INPUT_SHAPE))\n",
    "\n",
    "   #  conv_filters = 8\n",
    "   #  for _ in range(hparams[HP_CONV_LAYERS]):\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.Conv2D(\n",
    "   #           filters=conv_filters,\n",
    "   #          #  kernel_size=hparams[HP_CONV_KERNEL_SIZE],\n",
    "   #           kernel_size=3,\n",
    "   #           padding=\"same\",\n",
    "   #           activation=\"relu\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.MaxPooling2D(\n",
    "   #           pool_size=hparams[HP_POOL_SIZE],\n",
    "   #           strides=hparams[HP_POOL_SIZE]-1,\n",
    "   #           padding=\"same\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(tf.keras.layers.BatchNormalization())\n",
    "   #     conv_filters *= 2\n",
    "    \n",
    "    # 1st conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\\n\",\n",
    "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for _ in range(hparams[HP_DENSE_LAYERS]):\n",
    "        model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT], seed=rng.random()))\n",
    "\n",
    "    # output layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "       optimizer=hparams[HP_OPTIMIZER],\n",
    "       loss='sparse_categorical_crossentropy',\n",
    "       metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "#     fit_log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=fit_log_dir, histogram_freq=1)\n",
    "\n",
    "#     model.fit(x=x_train,\n",
    "#               y=y_train,\n",
    "#               validation_data=(x_validation, y_validation),\n",
    "#               batch_size=32,\n",
    "#               epochs=30,\n",
    "#               callbacks=[tensorboard_callback])\n",
    "    \n",
    "#     _, accuracy = model.evaluate(x_test, y_test)\n",
    "#     return accuracy\n",
    "\n",
    "\n",
    "# def run(run_dir, hparams):\n",
    "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
    "#     hp.hparams(hparams)  # record the values used in this trial\n",
    "#     accuracy = train_model(hparams)\n",
    "#     tf.summary.scalar(METRIC_ACCURACY, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(base_logdir, session_id, hparams):\n",
    "    model = create_model(hparams=hparams, seed=session_id)\n",
    "    logdir = os.path.join(base_logdir, session_id)\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logdir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "\n",
    "    hparams_callback = hp.KerasCallback(logdir, hparams)\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        validation_data=(x_validation, y_validation),\n",
    "        callbacks=[tensorboard_callback, hparams_callback]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(logdir, verbose=False):\n",
    "    rng = random.Random(0)\n",
    "\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=METRICS)\n",
    "\n",
    "    sessions_per_group = 2\n",
    "    num_sessions = NUM_SESSION_GROUPS * sessions_per_group\n",
    "    session_index = 0  # across all session groups\n",
    "    for group_index in range(NUM_SESSION_GROUPS):\n",
    "        hparams = {h: h.domain.sample_uniform(rng) for h in HPARAMS}\n",
    "        hparams_string = str(hparams)\n",
    "        for repeat_index in range(sessions_per_group):\n",
    "            session_id = str(session_index)\n",
    "            session_index += 1\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"--- Running training session %d/%d\"\n",
    "                    % (session_index, num_sessions)\n",
    "                )\n",
    "                print(hparams_string)\n",
    "                print(\"--- repeat #: %d\" % (repeat_index + 1))\n",
    "            run(\n",
    "                base_logdir=logdir,\n",
    "                session_id=session_id,\n",
    "                hparams=hparams,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to logs/hparam_tuning/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 23:17:47.499544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.636507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.637072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.638739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.639222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.639676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.829187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.829779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.829794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 23:17:47.830220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 23:17:47.830253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2875 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running training session 1/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.21214531345423326, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 23:17:49.601498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2023-12-18 23:17:49.933616: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-18 23:17:50.249530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf93e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-18 23:17:50.249605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 970, Compute Capability 5.2\n",
      "2023-12-18 23:17:50.448906: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-18 23:17:50.513257: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 6s 15ms/step - loss: 1.9317 - accuracy: 0.3190 - val_loss: 1.8571 - val_accuracy: 0.3056\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.4361 - accuracy: 0.4894 - val_loss: 1.4652 - val_accuracy: 0.4799\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1985 - accuracy: 0.5743 - val_loss: 1.5983 - val_accuracy: 0.4444\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0144 - accuracy: 0.6488 - val_loss: 1.1714 - val_accuracy: 0.5887\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8821 - accuracy: 0.6921 - val_loss: 1.0642 - val_accuracy: 0.6359\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7759 - accuracy: 0.7332 - val_loss: 1.4206 - val_accuracy: 0.5467\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6950 - accuracy: 0.7660 - val_loss: 1.2233 - val_accuracy: 0.5916\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6133 - accuracy: 0.7937 - val_loss: 1.2630 - val_accuracy: 0.6070\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5395 - accuracy: 0.8168 - val_loss: 1.1030 - val_accuracy: 0.6472\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4983 - accuracy: 0.8341 - val_loss: 1.2419 - val_accuracy: 0.6229\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4291 - accuracy: 0.8586 - val_loss: 0.9573 - val_accuracy: 0.6844\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3857 - accuracy: 0.8763 - val_loss: 1.1964 - val_accuracy: 0.6436\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3502 - accuracy: 0.8889 - val_loss: 1.1949 - val_accuracy: 0.6613\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3127 - accuracy: 0.8949 - val_loss: 0.9874 - val_accuracy: 0.6968\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2813 - accuracy: 0.9111 - val_loss: 1.2254 - val_accuracy: 0.6424\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2477 - accuracy: 0.9218 - val_loss: 0.9851 - val_accuracy: 0.7116\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2200 - accuracy: 0.9311 - val_loss: 0.9363 - val_accuracy: 0.7216\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1982 - accuracy: 0.9405 - val_loss: 0.8817 - val_accuracy: 0.7388\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1765 - accuracy: 0.9480 - val_loss: 1.3978 - val_accuracy: 0.6418\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1687 - accuracy: 0.9489 - val_loss: 0.8419 - val_accuracy: 0.7506\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1436 - accuracy: 0.9579 - val_loss: 1.1124 - val_accuracy: 0.7069\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1256 - accuracy: 0.9632 - val_loss: 1.6419 - val_accuracy: 0.6235\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1237 - accuracy: 0.9647 - val_loss: 1.1969 - val_accuracy: 0.6838\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1038 - accuracy: 0.9704 - val_loss: 0.9754 - val_accuracy: 0.7441\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0963 - accuracy: 0.9733 - val_loss: 0.7970 - val_accuracy: 0.7837\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0963 - accuracy: 0.9725 - val_loss: 1.0394 - val_accuracy: 0.7240\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0856 - accuracy: 0.9752 - val_loss: 1.2218 - val_accuracy: 0.7045\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0800 - accuracy: 0.9777 - val_loss: 1.0762 - val_accuracy: 0.7358\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.0731 - accuracy: 0.9792 - val_loss: 1.0750 - val_accuracy: 0.7329\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0662 - accuracy: 0.9821 - val_loss: 1.2146 - val_accuracy: 0.7139\n",
      "--- Running training session 2/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.21214531345423326, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 1.9583 - accuracy: 0.3113 - val_loss: 1.8547 - val_accuracy: 0.3304\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3724 - accuracy: 0.5174 - val_loss: 1.4671 - val_accuracy: 0.4657\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.1124 - accuracy: 0.6117 - val_loss: 1.1131 - val_accuracy: 0.6259\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.9432 - accuracy: 0.6755 - val_loss: 1.1616 - val_accuracy: 0.5993\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8206 - accuracy: 0.7228 - val_loss: 1.0048 - val_accuracy: 0.6613\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7100 - accuracy: 0.7575 - val_loss: 1.1522 - val_accuracy: 0.6176\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6181 - accuracy: 0.7890 - val_loss: 0.9814 - val_accuracy: 0.6874\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5352 - accuracy: 0.8212 - val_loss: 0.8847 - val_accuracy: 0.7204\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4705 - accuracy: 0.8400 - val_loss: 0.9109 - val_accuracy: 0.7092\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4122 - accuracy: 0.8657 - val_loss: 0.9082 - val_accuracy: 0.7175\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3731 - accuracy: 0.8790 - val_loss: 0.8366 - val_accuracy: 0.7335\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3288 - accuracy: 0.8921 - val_loss: 0.8264 - val_accuracy: 0.7335\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2848 - accuracy: 0.9074 - val_loss: 0.7674 - val_accuracy: 0.7630\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2543 - accuracy: 0.9195 - val_loss: 1.1472 - val_accuracy: 0.6862\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2264 - accuracy: 0.9316 - val_loss: 0.7691 - val_accuracy: 0.7719\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2022 - accuracy: 0.9369 - val_loss: 0.8702 - val_accuracy: 0.7547\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1793 - accuracy: 0.9444 - val_loss: 0.7152 - val_accuracy: 0.7937\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1640 - accuracy: 0.9478 - val_loss: 0.8843 - val_accuracy: 0.7618\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1485 - accuracy: 0.9539 - val_loss: 0.8602 - val_accuracy: 0.7618\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1326 - accuracy: 0.9616 - val_loss: 1.0882 - val_accuracy: 0.7258\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1119 - accuracy: 0.9699 - val_loss: 0.7535 - val_accuracy: 0.7908\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1099 - accuracy: 0.9656 - val_loss: 0.8029 - val_accuracy: 0.7801\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0934 - accuracy: 0.9727 - val_loss: 0.7496 - val_accuracy: 0.8061\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 0.8705 - val_accuracy: 0.7730\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0794 - accuracy: 0.9793 - val_loss: 0.8011 - val_accuracy: 0.7825\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0775 - accuracy: 0.9777 - val_loss: 0.8615 - val_accuracy: 0.7943\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0714 - accuracy: 0.9809 - val_loss: 0.7602 - val_accuracy: 0.8079\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.0666 - accuracy: 0.9820 - val_loss: 0.9119 - val_accuracy: 0.7813\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.0544 - accuracy: 0.9882 - val_loss: 0.8246 - val_accuracy: 0.8085\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0581 - accuracy: 0.9849 - val_loss: 0.8056 - val_accuracy: 0.8085\n",
      "--- Running training session 3/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4903399984760514, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 2.0911 - accuracy: 0.2739 - val_loss: 1.7605 - val_accuracy: 0.4043\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.5868 - accuracy: 0.4345 - val_loss: 1.4490 - val_accuracy: 0.4823\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3554 - accuracy: 0.5250 - val_loss: 1.2567 - val_accuracy: 0.5414\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.2101 - accuracy: 0.5739 - val_loss: 1.0907 - val_accuracy: 0.6076\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.0847 - accuracy: 0.6229 - val_loss: 0.9990 - val_accuracy: 0.6531\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.9861 - accuracy: 0.6594 - val_loss: 0.9811 - val_accuracy: 0.6418\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8944 - accuracy: 0.6989 - val_loss: 1.0204 - val_accuracy: 0.6365\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8167 - accuracy: 0.7202 - val_loss: 0.9080 - val_accuracy: 0.6838\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7326 - accuracy: 0.7475 - val_loss: 0.8845 - val_accuracy: 0.6998\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6924 - accuracy: 0.7640 - val_loss: 0.8765 - val_accuracy: 0.6974\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6288 - accuracy: 0.7903 - val_loss: 0.9828 - val_accuracy: 0.6720\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5666 - accuracy: 0.8110 - val_loss: 0.9776 - val_accuracy: 0.6909\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5113 - accuracy: 0.8286 - val_loss: 0.8585 - val_accuracy: 0.7240\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4912 - accuracy: 0.8382 - val_loss: 0.7969 - val_accuracy: 0.7465\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4343 - accuracy: 0.8553 - val_loss: 0.8022 - val_accuracy: 0.7476\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4054 - accuracy: 0.8698 - val_loss: 0.9947 - val_accuracy: 0.7027\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3879 - accuracy: 0.8726 - val_loss: 0.9088 - val_accuracy: 0.7240\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3584 - accuracy: 0.8831 - val_loss: 0.9642 - val_accuracy: 0.7086\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3190 - accuracy: 0.8951 - val_loss: 0.9649 - val_accuracy: 0.7240\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2967 - accuracy: 0.9035 - val_loss: 0.7621 - val_accuracy: 0.7736\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2849 - accuracy: 0.9059 - val_loss: 0.8381 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2660 - accuracy: 0.9113 - val_loss: 0.8340 - val_accuracy: 0.7600\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2429 - accuracy: 0.9215 - val_loss: 0.7204 - val_accuracy: 0.7884\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2204 - accuracy: 0.9320 - val_loss: 0.9126 - val_accuracy: 0.7541\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2056 - accuracy: 0.9353 - val_loss: 1.0045 - val_accuracy: 0.7488\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2069 - accuracy: 0.9360 - val_loss: 0.7278 - val_accuracy: 0.8032\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1758 - accuracy: 0.9431 - val_loss: 0.8713 - val_accuracy: 0.7677\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1726 - accuracy: 0.9462 - val_loss: 0.9318 - val_accuracy: 0.7606\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1637 - accuracy: 0.9481 - val_loss: 1.1829 - val_accuracy: 0.7258\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1451 - accuracy: 0.9536 - val_loss: 0.7546 - val_accuracy: 0.8056\n",
      "--- Running training session 4/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4903399984760514, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 2.1210 - accuracy: 0.2577 - val_loss: 1.8242 - val_accuracy: 0.3842\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.6386 - accuracy: 0.4227 - val_loss: 1.4347 - val_accuracy: 0.5290\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.4302 - accuracy: 0.5055 - val_loss: 1.2973 - val_accuracy: 0.5384\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.2453 - accuracy: 0.5616 - val_loss: 1.1432 - val_accuracy: 0.5904\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.1141 - accuracy: 0.6167 - val_loss: 1.0089 - val_accuracy: 0.6424\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.9966 - accuracy: 0.6608 - val_loss: 1.1665 - val_accuracy: 0.5910\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.9117 - accuracy: 0.6847 - val_loss: 0.9964 - val_accuracy: 0.6513\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8300 - accuracy: 0.7185 - val_loss: 0.9755 - val_accuracy: 0.6678\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7755 - accuracy: 0.7404 - val_loss: 1.0919 - val_accuracy: 0.6283\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6841 - accuracy: 0.7701 - val_loss: 0.8388 - val_accuracy: 0.7199\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6370 - accuracy: 0.7897 - val_loss: 0.8943 - val_accuracy: 0.7074\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5787 - accuracy: 0.8019 - val_loss: 0.9022 - val_accuracy: 0.7175\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5442 - accuracy: 0.8177 - val_loss: 0.8807 - val_accuracy: 0.7163\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4866 - accuracy: 0.8384 - val_loss: 0.7713 - val_accuracy: 0.7624\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4687 - accuracy: 0.8415 - val_loss: 0.7848 - val_accuracy: 0.7470\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4248 - accuracy: 0.8558 - val_loss: 0.8885 - val_accuracy: 0.7139\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3852 - accuracy: 0.8735 - val_loss: 0.8192 - val_accuracy: 0.7376\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3671 - accuracy: 0.8778 - val_loss: 0.8819 - val_accuracy: 0.7400\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3462 - accuracy: 0.8849 - val_loss: 0.7605 - val_accuracy: 0.7654\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3029 - accuracy: 0.9006 - val_loss: 0.7254 - val_accuracy: 0.7742\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2814 - accuracy: 0.9040 - val_loss: 0.8047 - val_accuracy: 0.7748\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2665 - accuracy: 0.9091 - val_loss: 0.7568 - val_accuracy: 0.7837\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2487 - accuracy: 0.9226 - val_loss: 0.8694 - val_accuracy: 0.7618\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2340 - accuracy: 0.9242 - val_loss: 0.9165 - val_accuracy: 0.7512\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2260 - accuracy: 0.9280 - val_loss: 0.8359 - val_accuracy: 0.7606\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2063 - accuracy: 0.9301 - val_loss: 0.9139 - val_accuracy: 0.7595\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1987 - accuracy: 0.9372 - val_loss: 1.0105 - val_accuracy: 0.7405\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1950 - accuracy: 0.9351 - val_loss: 0.7085 - val_accuracy: 0.7985\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1643 - accuracy: 0.9480 - val_loss: 0.6732 - val_accuracy: 0.8150\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1613 - accuracy: 0.9475 - val_loss: 0.7106 - val_accuracy: 0.8020\n",
      "--- Running training session 5/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3514060567452171, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 2.0197 - accuracy: 0.3404 - val_loss: 1.7728 - val_accuracy: 0.3936\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.3862 - accuracy: 0.5149 - val_loss: 1.4002 - val_accuracy: 0.4905\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.1445 - accuracy: 0.5941 - val_loss: 1.1936 - val_accuracy: 0.5928\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9988 - accuracy: 0.6500 - val_loss: 1.1633 - val_accuracy: 0.5957\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8838 - accuracy: 0.6902 - val_loss: 1.0651 - val_accuracy: 0.6460\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8004 - accuracy: 0.7179 - val_loss: 0.9231 - val_accuracy: 0.6856\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7115 - accuracy: 0.7507 - val_loss: 0.8937 - val_accuracy: 0.6826\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6534 - accuracy: 0.7748 - val_loss: 0.9663 - val_accuracy: 0.6826\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6089 - accuracy: 0.7945 - val_loss: 0.8360 - val_accuracy: 0.7293\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5594 - accuracy: 0.8051 - val_loss: 0.8164 - val_accuracy: 0.7222\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5082 - accuracy: 0.8293 - val_loss: 0.8427 - val_accuracy: 0.7246\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4616 - accuracy: 0.8491 - val_loss: 0.7499 - val_accuracy: 0.7524\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4269 - accuracy: 0.8543 - val_loss: 0.7487 - val_accuracy: 0.7612\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3882 - accuracy: 0.8689 - val_loss: 0.8291 - val_accuracy: 0.7476\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3715 - accuracy: 0.8762 - val_loss: 0.7259 - val_accuracy: 0.7760\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3517 - accuracy: 0.8840 - val_loss: 0.6984 - val_accuracy: 0.7914\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3139 - accuracy: 0.8994 - val_loss: 0.7206 - val_accuracy: 0.7778\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3004 - accuracy: 0.9023 - val_loss: 0.8063 - val_accuracy: 0.7636\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2898 - accuracy: 0.9037 - val_loss: 0.8223 - val_accuracy: 0.7506\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2722 - accuracy: 0.9062 - val_loss: 0.7485 - val_accuracy: 0.7796\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2397 - accuracy: 0.9241 - val_loss: 0.6637 - val_accuracy: 0.7967\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2389 - accuracy: 0.9211 - val_loss: 0.9030 - val_accuracy: 0.7340\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2264 - accuracy: 0.9264 - val_loss: 0.7827 - val_accuracy: 0.7813\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2113 - accuracy: 0.9292 - val_loss: 0.7577 - val_accuracy: 0.7760\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2079 - accuracy: 0.9316 - val_loss: 0.6739 - val_accuracy: 0.8044\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1863 - accuracy: 0.9410 - val_loss: 0.7241 - val_accuracy: 0.7837\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1728 - accuracy: 0.9447 - val_loss: 0.6817 - val_accuracy: 0.8044\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1624 - accuracy: 0.9481 - val_loss: 0.7039 - val_accuracy: 0.8056\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1536 - accuracy: 0.9508 - val_loss: 0.9010 - val_accuracy: 0.7577\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1516 - accuracy: 0.9545 - val_loss: 0.7458 - val_accuracy: 0.7890\n",
      "--- Running training session 6/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3514060567452171, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 1.9579 - accuracy: 0.3522 - val_loss: 1.9484 - val_accuracy: 0.3723\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.2975 - accuracy: 0.5492 - val_loss: 1.4647 - val_accuracy: 0.5053\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.0726 - accuracy: 0.6238 - val_loss: 1.4656 - val_accuracy: 0.5242\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9303 - accuracy: 0.6714 - val_loss: 1.0759 - val_accuracy: 0.6312\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8191 - accuracy: 0.7182 - val_loss: 1.1465 - val_accuracy: 0.6377\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7306 - accuracy: 0.7435 - val_loss: 0.9797 - val_accuracy: 0.6454\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6687 - accuracy: 0.7688 - val_loss: 0.8582 - val_accuracy: 0.7110\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6100 - accuracy: 0.7852 - val_loss: 0.9239 - val_accuracy: 0.6879\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5550 - accuracy: 0.8162 - val_loss: 0.8376 - val_accuracy: 0.7051\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5085 - accuracy: 0.8264 - val_loss: 1.4543 - val_accuracy: 0.6028\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4679 - accuracy: 0.8419 - val_loss: 0.8574 - val_accuracy: 0.7128\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4334 - accuracy: 0.8525 - val_loss: 0.8908 - val_accuracy: 0.6998\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4067 - accuracy: 0.8644 - val_loss: 0.7059 - val_accuracy: 0.7624\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3750 - accuracy: 0.8747 - val_loss: 1.0482 - val_accuracy: 0.6838\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3460 - accuracy: 0.8871 - val_loss: 0.8342 - val_accuracy: 0.7435\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3152 - accuracy: 0.8997 - val_loss: 1.1045 - val_accuracy: 0.6909\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2973 - accuracy: 0.9020 - val_loss: 0.9614 - val_accuracy: 0.7199\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2768 - accuracy: 0.9090 - val_loss: 1.1006 - val_accuracy: 0.6909\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2465 - accuracy: 0.9215 - val_loss: 0.7695 - val_accuracy: 0.7583\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2371 - accuracy: 0.9255 - val_loss: 0.7427 - val_accuracy: 0.7772\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2283 - accuracy: 0.9260 - val_loss: 0.9805 - val_accuracy: 0.7275\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2108 - accuracy: 0.9342 - val_loss: 0.8901 - val_accuracy: 0.7370\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1985 - accuracy: 0.9365 - val_loss: 0.7312 - val_accuracy: 0.7825\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1955 - accuracy: 0.9359 - val_loss: 1.0091 - val_accuracy: 0.7305\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1824 - accuracy: 0.9436 - val_loss: 0.6623 - val_accuracy: 0.8103\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1662 - accuracy: 0.9486 - val_loss: 0.9309 - val_accuracy: 0.7388\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.1635 - accuracy: 0.9490 - val_loss: 0.7514 - val_accuracy: 0.7760\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1562 - accuracy: 0.9509 - val_loss: 0.7021 - val_accuracy: 0.8002\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1514 - accuracy: 0.9558 - val_loss: 0.7548 - val_accuracy: 0.7825\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.1393 - accuracy: 0.9600 - val_loss: 0.6874 - val_accuracy: 0.8085\n",
      "--- Running training session 7/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3855106990025995, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 2.0805 - accuracy: 0.3183 - val_loss: 1.7036 - val_accuracy: 0.4025\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.4953 - accuracy: 0.4775 - val_loss: 1.2630 - val_accuracy: 0.5709\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.2930 - accuracy: 0.5582 - val_loss: 1.3181 - val_accuracy: 0.5491\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.1605 - accuracy: 0.5906 - val_loss: 1.2069 - val_accuracy: 0.5804\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.0499 - accuracy: 0.6303 - val_loss: 1.1874 - val_accuracy: 0.5839\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9679 - accuracy: 0.6622 - val_loss: 1.2008 - val_accuracy: 0.5798\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9082 - accuracy: 0.6825 - val_loss: 1.1061 - val_accuracy: 0.6135\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8465 - accuracy: 0.7012 - val_loss: 1.3066 - val_accuracy: 0.5751\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8067 - accuracy: 0.7215 - val_loss: 1.0299 - val_accuracy: 0.6436\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7444 - accuracy: 0.7438 - val_loss: 1.2393 - val_accuracy: 0.5875\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6980 - accuracy: 0.7564 - val_loss: 0.8198 - val_accuracy: 0.7234\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6575 - accuracy: 0.7685 - val_loss: 0.7789 - val_accuracy: 0.7435\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6088 - accuracy: 0.7893 - val_loss: 0.8048 - val_accuracy: 0.7382\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5850 - accuracy: 0.7973 - val_loss: 0.7526 - val_accuracy: 0.7470\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5500 - accuracy: 0.8067 - val_loss: 0.7467 - val_accuracy: 0.7589\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5212 - accuracy: 0.8155 - val_loss: 0.6652 - val_accuracy: 0.7796\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5004 - accuracy: 0.8212 - val_loss: 0.6272 - val_accuracy: 0.7908\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4757 - accuracy: 0.8339 - val_loss: 0.6511 - val_accuracy: 0.7967\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4532 - accuracy: 0.8449 - val_loss: 0.6893 - val_accuracy: 0.7801\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4514 - accuracy: 0.8384 - val_loss: 0.6406 - val_accuracy: 0.7973\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4271 - accuracy: 0.8463 - val_loss: 0.7073 - val_accuracy: 0.7784\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3988 - accuracy: 0.8583 - val_loss: 0.6526 - val_accuracy: 0.7902\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3957 - accuracy: 0.8595 - val_loss: 1.0061 - val_accuracy: 0.7222\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3648 - accuracy: 0.8692 - val_loss: 0.7990 - val_accuracy: 0.7535\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3578 - accuracy: 0.8719 - val_loss: 0.8270 - val_accuracy: 0.7624\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3588 - accuracy: 0.8737 - val_loss: 0.6762 - val_accuracy: 0.7961\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3363 - accuracy: 0.8818 - val_loss: 0.7729 - val_accuracy: 0.7796\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3210 - accuracy: 0.8858 - val_loss: 0.6646 - val_accuracy: 0.8002\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3224 - accuracy: 0.8855 - val_loss: 0.6359 - val_accuracy: 0.8115\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2977 - accuracy: 0.8939 - val_loss: 0.7199 - val_accuracy: 0.7896\n",
      "--- Running training session 8/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.3855106990025995, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 2.1256 - accuracy: 0.2862 - val_loss: 1.6818 - val_accuracy: 0.4025\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.5663 - accuracy: 0.4465 - val_loss: 1.3833 - val_accuracy: 0.5248\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.3511 - accuracy: 0.5239 - val_loss: 1.2590 - val_accuracy: 0.5621\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.1999 - accuracy: 0.5771 - val_loss: 1.5858 - val_accuracy: 0.4976\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.1008 - accuracy: 0.6126 - val_loss: 1.0909 - val_accuracy: 0.6312\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 1.0110 - accuracy: 0.6486 - val_loss: 1.1674 - val_accuracy: 0.6164\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9407 - accuracy: 0.6755 - val_loss: 1.1409 - val_accuracy: 0.5957\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8872 - accuracy: 0.6869 - val_loss: 0.9379 - val_accuracy: 0.6891\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8134 - accuracy: 0.7141 - val_loss: 0.8418 - val_accuracy: 0.7145\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7830 - accuracy: 0.7336 - val_loss: 0.8802 - val_accuracy: 0.6962\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7544 - accuracy: 0.7355 - val_loss: 0.8806 - val_accuracy: 0.6950\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6932 - accuracy: 0.7550 - val_loss: 0.8895 - val_accuracy: 0.6927\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6746 - accuracy: 0.7660 - val_loss: 1.0769 - val_accuracy: 0.6543\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6369 - accuracy: 0.7790 - val_loss: 0.7510 - val_accuracy: 0.7429\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5902 - accuracy: 0.7924 - val_loss: 0.8309 - val_accuracy: 0.7417\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5585 - accuracy: 0.8013 - val_loss: 0.8444 - val_accuracy: 0.7270\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5495 - accuracy: 0.7992 - val_loss: 0.7075 - val_accuracy: 0.7790\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5242 - accuracy: 0.8181 - val_loss: 0.7856 - val_accuracy: 0.7547\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4945 - accuracy: 0.8295 - val_loss: 0.7215 - val_accuracy: 0.7701\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4832 - accuracy: 0.8314 - val_loss: 0.7944 - val_accuracy: 0.7642\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4602 - accuracy: 0.8401 - val_loss: 0.7781 - val_accuracy: 0.7736\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4486 - accuracy: 0.8409 - val_loss: 0.7198 - val_accuracy: 0.7831\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4295 - accuracy: 0.8488 - val_loss: 0.8678 - val_accuracy: 0.7476\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4157 - accuracy: 0.8553 - val_loss: 0.8637 - val_accuracy: 0.7470\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3991 - accuracy: 0.8607 - val_loss: 0.6726 - val_accuracy: 0.7949\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3830 - accuracy: 0.8666 - val_loss: 0.7009 - val_accuracy: 0.7849\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3598 - accuracy: 0.8746 - val_loss: 0.7229 - val_accuracy: 0.7884\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3400 - accuracy: 0.8808 - val_loss: 0.7730 - val_accuracy: 0.7689\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3348 - accuracy: 0.8842 - val_loss: 0.7699 - val_accuracy: 0.7849\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3279 - accuracy: 0.8812 - val_loss: 0.8532 - val_accuracy: 0.7748\n",
      "--- Running training session 9/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4430651707989769, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 23:27:52.925894: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 6s 14ms/step - loss: 1.7114 - accuracy: 0.4065 - val_loss: 1.8354 - val_accuracy: 0.3582\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.1154 - accuracy: 0.6288 - val_loss: 2.0055 - val_accuracy: 0.3995\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8161 - accuracy: 0.7303 - val_loss: 1.2650 - val_accuracy: 0.6176\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.6255 - accuracy: 0.7985 - val_loss: 1.0126 - val_accuracy: 0.7027\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4798 - accuracy: 0.8416 - val_loss: 1.2214 - val_accuracy: 0.6767\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3940 - accuracy: 0.8715 - val_loss: 1.7928 - val_accuracy: 0.6028\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3387 - accuracy: 0.8908 - val_loss: 1.1903 - val_accuracy: 0.6968\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2580 - accuracy: 0.9125 - val_loss: 1.4322 - val_accuracy: 0.6986\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2210 - accuracy: 0.9317 - val_loss: 1.3683 - val_accuracy: 0.7074\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2126 - accuracy: 0.9351 - val_loss: 1.4138 - val_accuracy: 0.6939\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1571 - accuracy: 0.9514 - val_loss: 0.8282 - val_accuracy: 0.7943\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1466 - accuracy: 0.9514 - val_loss: 1.7516 - val_accuracy: 0.6655\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1202 - accuracy: 0.9608 - val_loss: 1.2620 - val_accuracy: 0.7429\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0997 - accuracy: 0.9684 - val_loss: 1.5376 - val_accuracy: 0.7400\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1423 - accuracy: 0.9573 - val_loss: 1.7025 - val_accuracy: 0.6838\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1260 - accuracy: 0.9620 - val_loss: 1.6882 - val_accuracy: 0.6909\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1149 - accuracy: 0.9648 - val_loss: 1.5197 - val_accuracy: 0.7400\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.9751 - val_accuracy: 0.8061\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 1.5065 - val_accuracy: 0.7660\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0554 - accuracy: 0.9837 - val_loss: 1.3248 - val_accuracy: 0.7660\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0781 - accuracy: 0.9784 - val_loss: 1.2078 - val_accuracy: 0.7872\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0917 - accuracy: 0.9744 - val_loss: 1.7258 - val_accuracy: 0.7335\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0824 - accuracy: 0.9765 - val_loss: 1.0861 - val_accuracy: 0.7707\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 0.9802 - val_loss: 1.5404 - val_accuracy: 0.7553\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 1.4338 - val_accuracy: 0.7748\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0567 - accuracy: 0.9840 - val_loss: 1.3962 - val_accuracy: 0.7571\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0638 - accuracy: 0.9812 - val_loss: 1.4303 - val_accuracy: 0.7784\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0492 - accuracy: 0.9858 - val_loss: 2.0066 - val_accuracy: 0.7376\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 1.2022 - val_accuracy: 0.8073\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0718 - accuracy: 0.9771 - val_loss: 3.2423 - val_accuracy: 0.6371\n",
      "--- Running training session 10/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 96, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.4430651707989769, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 14ms/step - loss: 1.6877 - accuracy: 0.4164 - val_loss: 1.4731 - val_accuracy: 0.4734\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.0778 - accuracy: 0.6312 - val_loss: 1.8987 - val_accuracy: 0.4639\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7822 - accuracy: 0.7339 - val_loss: 1.0045 - val_accuracy: 0.6850\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6157 - accuracy: 0.7983 - val_loss: 1.0462 - val_accuracy: 0.6944\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4632 - accuracy: 0.8520 - val_loss: 0.9792 - val_accuracy: 0.7157\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3622 - accuracy: 0.8806 - val_loss: 1.1882 - val_accuracy: 0.7086\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3185 - accuracy: 0.8973 - val_loss: 1.1441 - val_accuracy: 0.7187\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2565 - accuracy: 0.9196 - val_loss: 1.0550 - val_accuracy: 0.7541\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2043 - accuracy: 0.9354 - val_loss: 1.4892 - val_accuracy: 0.7063\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1961 - accuracy: 0.9424 - val_loss: 1.7843 - val_accuracy: 0.6726\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1593 - accuracy: 0.9509 - val_loss: 1.3064 - val_accuracy: 0.7329\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1320 - accuracy: 0.9600 - val_loss: 1.4916 - val_accuracy: 0.7063\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1457 - accuracy: 0.9546 - val_loss: 1.6722 - val_accuracy: 0.7187\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1388 - accuracy: 0.9567 - val_loss: 1.2472 - val_accuracy: 0.7742\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 1.1429 - val_accuracy: 0.7790\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 1.4756 - val_accuracy: 0.7370\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0996 - accuracy: 0.9702 - val_loss: 1.8864 - val_accuracy: 0.7163\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1004 - accuracy: 0.9685 - val_loss: 1.3464 - val_accuracy: 0.7748\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0812 - accuracy: 0.9744 - val_loss: 1.4606 - val_accuracy: 0.7346\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 1.1870 - val_accuracy: 0.7754\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0715 - accuracy: 0.9796 - val_loss: 2.2903 - val_accuracy: 0.6667\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0901 - accuracy: 0.9741 - val_loss: 1.7882 - val_accuracy: 0.6950\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0920 - accuracy: 0.9733 - val_loss: 1.6941 - val_accuracy: 0.7287\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 1.4201 - val_accuracy: 0.7754\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 1.3522 - val_accuracy: 0.7878\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0616 - accuracy: 0.9840 - val_loss: 1.4404 - val_accuracy: 0.7725\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0613 - accuracy: 0.9798 - val_loss: 1.4896 - val_accuracy: 0.7807\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0747 - accuracy: 0.9789 - val_loss: 1.6180 - val_accuracy: 0.7417\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 1.6395 - val_accuracy: 0.7583\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0611 - accuracy: 0.9845 - val_loss: 1.4393 - val_accuracy: 0.7725\n",
      "--- Running training session 11/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.41894952447803857, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 2.0209 - accuracy: 0.3316 - val_loss: 1.5270 - val_accuracy: 0.4622\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 1.4369 - accuracy: 0.5034 - val_loss: 1.2336 - val_accuracy: 0.5816\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1964 - accuracy: 0.5804 - val_loss: 1.4417 - val_accuracy: 0.5230\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.0526 - accuracy: 0.6296 - val_loss: 1.1530 - val_accuracy: 0.6147\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9441 - accuracy: 0.6683 - val_loss: 1.0083 - val_accuracy: 0.6501\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8661 - accuracy: 0.7009 - val_loss: 0.9659 - val_accuracy: 0.6673\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7833 - accuracy: 0.7272 - val_loss: 0.8752 - val_accuracy: 0.6992\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7342 - accuracy: 0.7442 - val_loss: 0.8297 - val_accuracy: 0.7240\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6780 - accuracy: 0.7680 - val_loss: 0.7883 - val_accuracy: 0.7358\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.6399 - accuracy: 0.7790 - val_loss: 0.8736 - val_accuracy: 0.7074\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5949 - accuracy: 0.7983 - val_loss: 0.9091 - val_accuracy: 0.6850\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5553 - accuracy: 0.8107 - val_loss: 0.7775 - val_accuracy: 0.7435\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5079 - accuracy: 0.8149 - val_loss: 0.8258 - val_accuracy: 0.7264\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4912 - accuracy: 0.8330 - val_loss: 0.7940 - val_accuracy: 0.7317\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4620 - accuracy: 0.8410 - val_loss: 0.8924 - val_accuracy: 0.7169\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4432 - accuracy: 0.8454 - val_loss: 0.8115 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4293 - accuracy: 0.8502 - val_loss: 0.7658 - val_accuracy: 0.7453\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3979 - accuracy: 0.8636 - val_loss: 0.8859 - val_accuracy: 0.7553\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3746 - accuracy: 0.8729 - val_loss: 0.7767 - val_accuracy: 0.7571\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3593 - accuracy: 0.8784 - val_loss: 1.0533 - val_accuracy: 0.6927\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3491 - accuracy: 0.8800 - val_loss: 0.7270 - val_accuracy: 0.7748\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3208 - accuracy: 0.8896 - val_loss: 0.6484 - val_accuracy: 0.7996\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3000 - accuracy: 0.8986 - val_loss: 0.6380 - val_accuracy: 0.7961\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2881 - accuracy: 0.9017 - val_loss: 0.7992 - val_accuracy: 0.7530\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2733 - accuracy: 0.9082 - val_loss: 0.8655 - val_accuracy: 0.7394\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2568 - accuracy: 0.9118 - val_loss: 0.6722 - val_accuracy: 0.7985\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2586 - accuracy: 0.9093 - val_loss: 0.6491 - val_accuracy: 0.8109\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2430 - accuracy: 0.9171 - val_loss: 0.6624 - val_accuracy: 0.8008\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2383 - accuracy: 0.9192 - val_loss: 0.6245 - val_accuracy: 0.8097\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2186 - accuracy: 0.9258 - val_loss: 0.7275 - val_accuracy: 0.7801\n",
      "--- Running training session 12/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.41894952447803857, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 13ms/step - loss: 2.0836 - accuracy: 0.3160 - val_loss: 1.6788 - val_accuracy: 0.4184\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.4439 - accuracy: 0.4898 - val_loss: 1.4203 - val_accuracy: 0.4923\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.1871 - accuracy: 0.5928 - val_loss: 1.1852 - val_accuracy: 0.5910\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 1.0197 - accuracy: 0.6436 - val_loss: 1.0544 - val_accuracy: 0.6324\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.9140 - accuracy: 0.6865 - val_loss: 1.0067 - val_accuracy: 0.6543\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.8224 - accuracy: 0.7206 - val_loss: 1.0754 - val_accuracy: 0.6229\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.7784 - accuracy: 0.7348 - val_loss: 1.0356 - val_accuracy: 0.6430\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.7032 - accuracy: 0.7605 - val_loss: 0.9004 - val_accuracy: 0.6897\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.6699 - accuracy: 0.7698 - val_loss: 0.9396 - val_accuracy: 0.6820\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6228 - accuracy: 0.7920 - val_loss: 0.7968 - val_accuracy: 0.7270\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5845 - accuracy: 0.7964 - val_loss: 0.6949 - val_accuracy: 0.7571\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.5453 - accuracy: 0.8135 - val_loss: 0.8086 - val_accuracy: 0.7281\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.5100 - accuracy: 0.8237 - val_loss: 0.7554 - val_accuracy: 0.7470\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4838 - accuracy: 0.8373 - val_loss: 0.8008 - val_accuracy: 0.7411\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.4640 - accuracy: 0.8400 - val_loss: 0.6673 - val_accuracy: 0.7636\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4197 - accuracy: 0.8546 - val_loss: 0.6610 - val_accuracy: 0.7931\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4119 - accuracy: 0.8614 - val_loss: 0.7053 - val_accuracy: 0.7784\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.4009 - accuracy: 0.8635 - val_loss: 1.0808 - val_accuracy: 0.6797\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3721 - accuracy: 0.8731 - val_loss: 0.5825 - val_accuracy: 0.8050\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.3533 - accuracy: 0.8753 - val_loss: 0.7798 - val_accuracy: 0.7518\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.3264 - accuracy: 0.8867 - val_loss: 0.7164 - val_accuracy: 0.7671\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3132 - accuracy: 0.8887 - val_loss: 0.6344 - val_accuracy: 0.8032\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2970 - accuracy: 0.8942 - val_loss: 0.6405 - val_accuracy: 0.7937\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2924 - accuracy: 0.9003 - val_loss: 0.7312 - val_accuracy: 0.7790\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2760 - accuracy: 0.9062 - val_loss: 0.8633 - val_accuracy: 0.7524\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2743 - accuracy: 0.9053 - val_loss: 0.7511 - val_accuracy: 0.7784\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2545 - accuracy: 0.9162 - val_loss: 0.9411 - val_accuracy: 0.7335\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2386 - accuracy: 0.9177 - val_loss: 0.8797 - val_accuracy: 0.7636\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 2s 11ms/step - loss: 0.2296 - accuracy: 0.9241 - val_loss: 0.7435 - val_accuracy: 0.7778\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 2s 12ms/step - loss: 0.2470 - accuracy: 0.9152 - val_loss: 0.7030 - val_accuracy: 0.7955\n",
      "--- Running training session 13/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.23021036242050974, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 14ms/step - loss: 1.9922 - accuracy: 0.2850 - val_loss: 1.7526 - val_accuracy: 0.3741\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.5251 - accuracy: 0.4582 - val_loss: 1.4131 - val_accuracy: 0.4811\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3027 - accuracy: 0.5371 - val_loss: 1.3799 - val_accuracy: 0.4888\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1317 - accuracy: 0.5999 - val_loss: 1.4401 - val_accuracy: 0.5035\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.9799 - accuracy: 0.6563 - val_loss: 1.1123 - val_accuracy: 0.5987\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.8559 - accuracy: 0.6996 - val_loss: 1.0858 - val_accuracy: 0.6141\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.7523 - accuracy: 0.7416 - val_loss: 1.0546 - val_accuracy: 0.6401\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6629 - accuracy: 0.7730 - val_loss: 0.9781 - val_accuracy: 0.6708\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5739 - accuracy: 0.8056 - val_loss: 1.3150 - val_accuracy: 0.5804\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4972 - accuracy: 0.8347 - val_loss: 1.0205 - val_accuracy: 0.6856\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.4426 - accuracy: 0.8517 - val_loss: 0.9223 - val_accuracy: 0.7057\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3893 - accuracy: 0.8728 - val_loss: 0.8460 - val_accuracy: 0.7340\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3336 - accuracy: 0.8910 - val_loss: 0.9771 - val_accuracy: 0.6956\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2964 - accuracy: 0.9028 - val_loss: 0.8275 - val_accuracy: 0.7506\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2584 - accuracy: 0.9176 - val_loss: 0.8201 - val_accuracy: 0.7630\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2286 - accuracy: 0.9291 - val_loss: 0.9737 - val_accuracy: 0.7216\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1992 - accuracy: 0.9366 - val_loss: 1.0860 - val_accuracy: 0.7181\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1743 - accuracy: 0.9486 - val_loss: 0.7497 - val_accuracy: 0.7825\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1606 - accuracy: 0.9515 - val_loss: 0.9671 - val_accuracy: 0.7329\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1293 - accuracy: 0.9613 - val_loss: 0.9905 - val_accuracy: 0.7482\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1214 - accuracy: 0.9639 - val_loss: 1.0077 - val_accuracy: 0.7547\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1199 - accuracy: 0.9648 - val_loss: 0.9565 - val_accuracy: 0.7547\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0972 - accuracy: 0.9718 - val_loss: 1.0064 - val_accuracy: 0.7524\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0774 - accuracy: 0.9784 - val_loss: 1.0941 - val_accuracy: 0.7447\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0813 - accuracy: 0.9768 - val_loss: 1.1880 - val_accuracy: 0.7281\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.9460 - val_accuracy: 0.7671\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0693 - accuracy: 0.9796 - val_loss: 1.0518 - val_accuracy: 0.7671\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 1.2244 - val_accuracy: 0.7376\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.9916 - val_accuracy: 0.7784\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0518 - accuracy: 0.9863 - val_loss: 1.1543 - val_accuracy: 0.7583\n",
      "--- Running training session 14/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.23021036242050974, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 4s 15ms/step - loss: 1.9891 - accuracy: 0.2806 - val_loss: 1.7871 - val_accuracy: 0.3534\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.5480 - accuracy: 0.4514 - val_loss: 1.4907 - val_accuracy: 0.4710\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.3076 - accuracy: 0.5420 - val_loss: 1.3746 - val_accuracy: 0.5207\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 1.1135 - accuracy: 0.6184 - val_loss: 1.6112 - val_accuracy: 0.4888\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.9752 - accuracy: 0.6618 - val_loss: 1.4147 - val_accuracy: 0.5230\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8570 - accuracy: 0.7107 - val_loss: 1.1981 - val_accuracy: 0.5892\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.7348 - accuracy: 0.7546 - val_loss: 1.1217 - val_accuracy: 0.6383\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.6506 - accuracy: 0.7853 - val_loss: 1.2117 - val_accuracy: 0.6212\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.5721 - accuracy: 0.8122 - val_loss: 1.4374 - val_accuracy: 0.5946\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.5140 - accuracy: 0.8329 - val_loss: 1.3436 - val_accuracy: 0.6283\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4509 - accuracy: 0.8503 - val_loss: 1.2196 - val_accuracy: 0.6472\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3862 - accuracy: 0.8746 - val_loss: 0.9603 - val_accuracy: 0.7027\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3428 - accuracy: 0.8890 - val_loss: 1.0272 - val_accuracy: 0.7033\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.3102 - accuracy: 0.8985 - val_loss: 1.4637 - val_accuracy: 0.6466\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2596 - accuracy: 0.9202 - val_loss: 1.0480 - val_accuracy: 0.6956\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2333 - accuracy: 0.9267 - val_loss: 0.9462 - val_accuracy: 0.7364\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.2030 - accuracy: 0.9382 - val_loss: 1.2461 - val_accuracy: 0.6832\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1752 - accuracy: 0.9467 - val_loss: 1.2380 - val_accuracy: 0.6962\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.1808 - accuracy: 0.9433 - val_loss: 1.4749 - val_accuracy: 0.6554\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1392 - accuracy: 0.9588 - val_loss: 1.7476 - val_accuracy: 0.6283\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1174 - accuracy: 0.9656 - val_loss: 1.3271 - val_accuracy: 0.6962\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1084 - accuracy: 0.9684 - val_loss: 1.1084 - val_accuracy: 0.7441\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1098 - accuracy: 0.9673 - val_loss: 1.1466 - val_accuracy: 0.7311\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0947 - accuracy: 0.9731 - val_loss: 1.1697 - val_accuracy: 0.7388\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0678 - accuracy: 0.9827 - val_loss: 1.1181 - val_accuracy: 0.7512\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0691 - accuracy: 0.9796 - val_loss: 1.1139 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0566 - accuracy: 0.9858 - val_loss: 0.9733 - val_accuracy: 0.7807\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0474 - accuracy: 0.9882 - val_loss: 1.0317 - val_accuracy: 0.7683\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0498 - accuracy: 0.9871 - val_loss: 0.9836 - val_accuracy: 0.7837\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 1.0111 - val_accuracy: 0.7825\n",
      "--- Running training session 15/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.39212702046262704, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/30\n",
      "212/212 [==============================] - 6s 15ms/step - loss: 1.7468 - accuracy: 0.3933 - val_loss: 1.4750 - val_accuracy: 0.4569\n",
      "Epoch 2/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 1.1532 - accuracy: 0.6157 - val_loss: 1.6771 - val_accuracy: 0.4657\n",
      "Epoch 3/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.8437 - accuracy: 0.7241 - val_loss: 1.7376 - val_accuracy: 0.5195\n",
      "Epoch 4/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.6481 - accuracy: 0.7871 - val_loss: 1.0154 - val_accuracy: 0.6720\n",
      "Epoch 5/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4963 - accuracy: 0.8379 - val_loss: 1.0790 - val_accuracy: 0.6761\n",
      "Epoch 6/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.4284 - accuracy: 0.8602 - val_loss: 1.1806 - val_accuracy: 0.6708\n",
      "Epoch 7/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.3439 - accuracy: 0.8898 - val_loss: 1.6730 - val_accuracy: 0.6117\n",
      "Epoch 8/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2830 - accuracy: 0.9097 - val_loss: 1.4816 - val_accuracy: 0.6554\n",
      "Epoch 9/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.2457 - accuracy: 0.9235 - val_loss: 1.4493 - val_accuracy: 0.6407\n",
      "Epoch 10/30\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.2136 - accuracy: 0.9314 - val_loss: 1.6567 - val_accuracy: 0.6755\n",
      "Epoch 11/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1812 - accuracy: 0.9444 - val_loss: 1.2461 - val_accuracy: 0.7134\n",
      "Epoch 12/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1572 - accuracy: 0.9529 - val_loss: 1.2117 - val_accuracy: 0.7417\n",
      "Epoch 13/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1646 - accuracy: 0.9508 - val_loss: 1.4290 - val_accuracy: 0.6944\n",
      "Epoch 14/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1613 - accuracy: 0.9477 - val_loss: 2.1456 - val_accuracy: 0.6259\n",
      "Epoch 15/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1289 - accuracy: 0.9591 - val_loss: 1.6866 - val_accuracy: 0.7080\n",
      "Epoch 16/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1200 - accuracy: 0.9634 - val_loss: 1.2350 - val_accuracy: 0.7577\n",
      "Epoch 17/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1061 - accuracy: 0.9676 - val_loss: 1.1835 - val_accuracy: 0.7636\n",
      "Epoch 18/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0905 - accuracy: 0.9750 - val_loss: 1.4233 - val_accuracy: 0.7110\n",
      "Epoch 19/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0889 - accuracy: 0.9768 - val_loss: 1.4188 - val_accuracy: 0.7417\n",
      "Epoch 20/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 1.6363 - val_accuracy: 0.7063\n",
      "Epoch 21/30\n",
      "212/212 [==============================] - 3s 12ms/step - loss: 0.0760 - accuracy: 0.9780 - val_loss: 1.9870 - val_accuracy: 0.6956\n",
      "Epoch 22/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.1158 - accuracy: 0.9653 - val_loss: 1.2880 - val_accuracy: 0.7636\n",
      "Epoch 23/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0726 - accuracy: 0.9799 - val_loss: 2.5495 - val_accuracy: 0.6584\n",
      "Epoch 24/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0641 - accuracy: 0.9793 - val_loss: 1.5949 - val_accuracy: 0.7470\n",
      "Epoch 25/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 1.5316 - val_accuracy: 0.7577\n",
      "Epoch 26/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0890 - accuracy: 0.9736 - val_loss: 1.7154 - val_accuracy: 0.7346\n",
      "Epoch 27/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0681 - accuracy: 0.9806 - val_loss: 1.2622 - val_accuracy: 0.7470\n",
      "Epoch 28/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0717 - accuracy: 0.9802 - val_loss: 1.4424 - val_accuracy: 0.7606\n",
      "Epoch 29/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 2.1074 - val_accuracy: 0.6944\n",
      "Epoch 30/30\n",
      "212/212 [==============================] - 3s 13ms/step - loss: 0.0678 - accuracy: 0.9812 - val_loss: 1.3428 - val_accuracy: 0.7748\n",
      "--- Running training session 16/20\n",
      "{HParam(name='num_units', domain=Discrete([32, 64, 96]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.5), display_name=None, description=None): 0.39212702046262704, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 2\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "np.random.seed(0)\n",
    "logdir = LOGDIR\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(f\"Saving output to {logdir}\")\n",
    "run_all(logdir=logdir, verbose=True)\n",
    "print(f\"Done. Output saved to {logdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fd12ed56f5e1435\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fd12ed56f5e1435\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
