{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 22:05:18.218788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 22:05:19.116115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data.json\"\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 # percentage of dataset\n",
    "TEST_SPLIT = 0.1 # percentage of dataset\n",
    "\n",
    "NUM_SESSION_GROUPS = 5\n",
    "LOGDIR = \"logs/hparam_tuning/\"\n",
    "CHECKPOINT_DIR = \"logs/checkpoint\"\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from json file\n",
    "\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "x = np.array(data[\"mfcc\"])\n",
    "y = np.array(data[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SPLIT)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=VALIDATION_SPLIT)\n",
    "\n",
    "# add an axis to input sets to match the shape CNN expects (last axis is like channel in color images)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "x_validation = x_validation[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose hyperparameters to tune\n",
    "\n",
    "# HP_CONV_LAYERS = hp.HParam(\"conv_layers\", hp.IntInterval(1, 3))\n",
    "# HP_CONV_KERNEL_SIZE = hp.HParam(\"conv_kernel_size\", hp.Discrete([3, 5]))\n",
    "# HP_POOL_SIZE = hp.HParam(\"conv_pool_size\", hp.Discrete([2, 3]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64]))\n",
    "HP_DENSE_LAYERS = hp.HParam(\"dense_layers\", hp.IntInterval(1, 3))\n",
    "HP_DROPOUT = hp.HParam(\"dropout\", hp.RealInterval(0.2, 0.3))\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", hp.Discrete([\"adam\", \"sgd\"]))\n",
    "\n",
    "HPARAMS = [\n",
    "    # HP_CONV_LAYERS,\n",
    "    # HP_CONV_KERNEL_SIZE,\n",
    "    # HP_POOL_SIZE,\n",
    "    HP_NUM_UNITS,\n",
    "    HP_DENSE_LAYERS,\n",
    "    HP_DROPOUT,\n",
    "    HP_OPTIMIZER\n",
    "]\n",
    "\n",
    "METRICS = [\n",
    "    hp.Metric(\n",
    "        \"epoch_accuracy\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"accuracy (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"epoch_loss\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"loss (val)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_accuracy\",\n",
    "        group=\"train\",\n",
    "        display_name=\"accuracy (train)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_loss\",\n",
    "        group=\"train\",\n",
    "        display_name=\"loss (train)\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams, seed):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    INPUT_SHAPE = (x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=INPUT_SHAPE))\n",
    "\n",
    "   #  conv_filters = 8\n",
    "   #  for _ in range(hparams[HP_CONV_LAYERS]):\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.Conv2D(\n",
    "   #           filters=conv_filters,\n",
    "   #          #  kernel_size=hparams[HP_CONV_KERNEL_SIZE],\n",
    "   #           kernel_size=3,\n",
    "   #           padding=\"same\",\n",
    "   #           activation=\"relu\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(\n",
    "   #        tf.keras.layers.MaxPooling2D(\n",
    "   #           pool_size=hparams[HP_POOL_SIZE],\n",
    "   #           strides=hparams[HP_POOL_SIZE]-1,\n",
    "   #           padding=\"same\"\n",
    "   #        )\n",
    "   #     )\n",
    "   #     model.add(tf.keras.layers.BatchNormalization())\n",
    "   #     conv_filters *= 2\n",
    "    \n",
    "    # 1st conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\\n\",\n",
    "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for _ in range(hparams[HP_DENSE_LAYERS]):\n",
    "        model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT], seed=rng.random()))\n",
    "\n",
    "    # output layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "       optimizer=hparams[HP_OPTIMIZER],\n",
    "       loss='sparse_categorical_crossentropy',\n",
    "       metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(base_logdir, session_id, hparams):\n",
    "    model = create_model(hparams=hparams, seed=session_id)\n",
    "    logdir = os.path.join(base_logdir, session_id)\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logdir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "\n",
    "    hparams_callback = hp.KerasCallback(logdir, hparams)\n",
    "\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=CHECKPOINT_DIR,\n",
    "        save_weights_only=True,\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        validation_data=(x_validation, y_validation),\n",
    "        callbacks=[tensorboard_callback, hparams_callback, checkpoint_callback]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(logdir, verbose=True):\n",
    "    rng = random.Random(0)\n",
    "\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=METRICS)\n",
    "\n",
    "    sessions_per_group = 2\n",
    "    num_sessions = NUM_SESSION_GROUPS * sessions_per_group\n",
    "    session_index = 0  # across all session groups\n",
    "    for group_index in range(NUM_SESSION_GROUPS):\n",
    "        hparams = {h: h.domain.sample_uniform(rng) for h in HPARAMS}\n",
    "        hparams_string = str(hparams)\n",
    "        for repeat_index in range(sessions_per_group):\n",
    "            session_id = str(session_index)\n",
    "            session_index += 1\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"--- Running training session %d/%d\"\n",
    "                    % (session_index, num_sessions)\n",
    "                )\n",
    "                print(hparams_string)\n",
    "                print(\"--- repeat #: %d\" % (repeat_index + 1))\n",
    "            model = run(\n",
    "                base_logdir=logdir,\n",
    "                session_id=session_id,\n",
    "                hparams=hparams,\n",
    "            )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to logs/hparam_tuning/\n",
      "--- Running training session 1/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.20404843781807777, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 22:06:06.052055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.339710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.340168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.342135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.342670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.343098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.582233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.583218: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.583256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-19 22:06:06.583873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 22:06:06.584205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2875 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 22:06:08.663415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2023-12-19 22:06:08.984835: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-19 22:06:09.287086: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9507c75190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-19 22:06:09.287222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 970, Compute Capability 5.2\n",
      "2023-12-19 22:06:09.598412: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-19 22:06:09.684428: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/135 [============================>.] - ETA: 0s - loss: 2.0255 - accuracy: 0.2808\n",
      "Epoch 1: val_accuracy improved from -inf to 0.32130, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 5s 16ms/step - loss: 2.0224 - accuracy: 0.2817 - val_loss: 1.9604 - val_accuracy: 0.3213\n",
      "Epoch 2/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.5221 - accuracy: 0.4707\n",
      "Epoch 2: val_accuracy improved from 0.32130 to 0.49722, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.5161 - accuracy: 0.4713 - val_loss: 1.4982 - val_accuracy: 0.4972\n",
      "Epoch 3/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 1.2940 - accuracy: 0.5585\n",
      "Epoch 3: val_accuracy improved from 0.49722 to 0.52222, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.2912 - accuracy: 0.5600 - val_loss: 1.3902 - val_accuracy: 0.5222\n",
      "Epoch 4/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 1.1154 - accuracy: 0.6117\n",
      "Epoch 4: val_accuracy improved from 0.52222 to 0.54537, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.1145 - accuracy: 0.6125 - val_loss: 1.3100 - val_accuracy: 0.5454\n",
      "Epoch 5/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.9758 - accuracy: 0.6622\n",
      "Epoch 5: val_accuracy improved from 0.54537 to 0.56019, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.9756 - accuracy: 0.6618 - val_loss: 1.2448 - val_accuracy: 0.5602\n",
      "Epoch 6/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.8752 - accuracy: 0.7030\n",
      "Epoch 6: val_accuracy improved from 0.56019 to 0.64630, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.8777 - accuracy: 0.7037 - val_loss: 1.0507 - val_accuracy: 0.6463\n",
      "Epoch 7/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.7736 - accuracy: 0.7391\n",
      "Epoch 7: val_accuracy did not improve from 0.64630\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.7749 - accuracy: 0.7384 - val_loss: 1.2689 - val_accuracy: 0.5750\n",
      "Epoch 8/20\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.6790 - accuracy: 0.7684\n",
      "Epoch 8: val_accuracy did not improve from 0.64630\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.6796 - accuracy: 0.7681 - val_loss: 1.1495 - val_accuracy: 0.6222\n",
      "Epoch 9/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.8042\n",
      "Epoch 9: val_accuracy improved from 0.64630 to 0.68981, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6007 - accuracy: 0.8046 - val_loss: 1.0032 - val_accuracy: 0.6898\n",
      "Epoch 10/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.5219 - accuracy: 0.8326\n",
      "Epoch 10: val_accuracy did not improve from 0.68981\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.5209 - accuracy: 0.8331 - val_loss: 1.0904 - val_accuracy: 0.6472\n",
      "Epoch 11/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.4651 - accuracy: 0.8541\n",
      "Epoch 11: val_accuracy improved from 0.68981 to 0.70000, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4653 - accuracy: 0.8546 - val_loss: 0.9848 - val_accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.4043 - accuracy: 0.8690\n",
      "Epoch 12: val_accuracy improved from 0.70000 to 0.71574, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4037 - accuracy: 0.8694 - val_loss: 0.9359 - val_accuracy: 0.7157\n",
      "Epoch 13/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.8905\n",
      "Epoch 13: val_accuracy did not improve from 0.71574\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3620 - accuracy: 0.8894 - val_loss: 1.0440 - val_accuracy: 0.6769\n",
      "Epoch 14/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8984\n",
      "Epoch 14: val_accuracy improved from 0.71574 to 0.72037, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3251 - accuracy: 0.8981 - val_loss: 1.0044 - val_accuracy: 0.7204\n",
      "Epoch 15/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2895 - accuracy: 0.9141\n",
      "Epoch 15: val_accuracy did not improve from 0.72037\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2917 - accuracy: 0.9123 - val_loss: 0.9659 - val_accuracy: 0.7157\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9252\n",
      "Epoch 16: val_accuracy improved from 0.72037 to 0.73426, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2492 - accuracy: 0.9252 - val_loss: 0.9122 - val_accuracy: 0.7343\n",
      "Epoch 17/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9333\n",
      "Epoch 17: val_accuracy did not improve from 0.73426\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2338 - accuracy: 0.9336 - val_loss: 1.0104 - val_accuracy: 0.7019\n",
      "Epoch 18/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.2012 - accuracy: 0.9417\n",
      "Epoch 18: val_accuracy did not improve from 0.73426\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2002 - accuracy: 0.9424 - val_loss: 1.0335 - val_accuracy: 0.7102\n",
      "Epoch 19/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9545\n",
      "Epoch 19: val_accuracy did not improve from 0.73426\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.1701 - accuracy: 0.9546 - val_loss: 1.1216 - val_accuracy: 0.7037\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9525\n",
      "Epoch 20: val_accuracy did not improve from 0.73426\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1628 - accuracy: 0.9525 - val_loss: 1.0081 - val_accuracy: 0.7278\n",
      "--- Running training session 2/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.20404843781807777, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 2.1027 - accuracy: 0.2630\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17778, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 3s 14ms/step - loss: 2.1027 - accuracy: 0.2630 - val_loss: 2.1787 - val_accuracy: 0.1778\n",
      "Epoch 2/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.5744 - accuracy: 0.4525\n",
      "Epoch 2: val_accuracy improved from 0.17778 to 0.47037, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.5736 - accuracy: 0.4528 - val_loss: 1.5327 - val_accuracy: 0.4704\n",
      "Epoch 3/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 1.3068 - accuracy: 0.5469\n",
      "Epoch 3: val_accuracy improved from 0.47037 to 0.56111, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.3078 - accuracy: 0.5463 - val_loss: 1.2700 - val_accuracy: 0.5611\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.1032 - accuracy: 0.6257\n",
      "Epoch 4: val_accuracy improved from 0.56111 to 0.62222, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.1032 - accuracy: 0.6257 - val_loss: 1.1273 - val_accuracy: 0.6222\n",
      "Epoch 5/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.9729 - accuracy: 0.6698\n",
      "Epoch 5: val_accuracy did not improve from 0.62222\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.9712 - accuracy: 0.6711 - val_loss: 1.0834 - val_accuracy: 0.6213\n",
      "Epoch 6/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.8500 - accuracy: 0.7173\n",
      "Epoch 6: val_accuracy improved from 0.62222 to 0.65741, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.8523 - accuracy: 0.7164 - val_loss: 1.0178 - val_accuracy: 0.6574\n",
      "Epoch 7/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.7599 - accuracy: 0.7521\n",
      "Epoch 7: val_accuracy improved from 0.65741 to 0.69907, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.7588 - accuracy: 0.7521 - val_loss: 0.9014 - val_accuracy: 0.6991\n",
      "Epoch 8/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7743\n",
      "Epoch 8: val_accuracy improved from 0.69907 to 0.70000, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6748 - accuracy: 0.7736 - val_loss: 0.8908 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.5997 - accuracy: 0.8003\n",
      "Epoch 9: val_accuracy did not improve from 0.70000\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.6013 - accuracy: 0.8005 - val_loss: 0.8651 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.5365 - accuracy: 0.8281\n",
      "Epoch 10: val_accuracy improved from 0.70000 to 0.70370, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.5383 - accuracy: 0.8273 - val_loss: 0.8794 - val_accuracy: 0.7037\n",
      "Epoch 11/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.4828 - accuracy: 0.8466\n",
      "Epoch 11: val_accuracy improved from 0.70370 to 0.72037, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4831 - accuracy: 0.8463 - val_loss: 0.8511 - val_accuracy: 0.7204\n",
      "Epoch 12/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.8766\n",
      "Epoch 12: val_accuracy did not improve from 0.72037\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4130 - accuracy: 0.8766 - val_loss: 0.8958 - val_accuracy: 0.7009\n",
      "Epoch 13/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8813\n",
      "Epoch 13: val_accuracy improved from 0.72037 to 0.73519, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3802 - accuracy: 0.8819 - val_loss: 0.8534 - val_accuracy: 0.7352\n",
      "Epoch 14/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8947\n",
      "Epoch 14: val_accuracy did not improve from 0.73519\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3313 - accuracy: 0.8949 - val_loss: 1.0012 - val_accuracy: 0.6769\n",
      "Epoch 15/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.3044 - accuracy: 0.9089\n",
      "Epoch 15: val_accuracy improved from 0.73519 to 0.73611, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3037 - accuracy: 0.9090 - val_loss: 0.8982 - val_accuracy: 0.7361\n",
      "Epoch 16/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9222\n",
      "Epoch 16: val_accuracy did not improve from 0.73611\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2650 - accuracy: 0.9222 - val_loss: 0.8923 - val_accuracy: 0.7324\n",
      "Epoch 17/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.2322 - accuracy: 0.9363\n",
      "Epoch 17: val_accuracy improved from 0.73611 to 0.74352, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2317 - accuracy: 0.9368 - val_loss: 0.8445 - val_accuracy: 0.7435\n",
      "Epoch 18/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9478\n",
      "Epoch 18: val_accuracy improved from 0.74352 to 0.75741, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1936 - accuracy: 0.9479 - val_loss: 0.8321 - val_accuracy: 0.7574\n",
      "Epoch 19/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9485\n",
      "Epoch 19: val_accuracy improved from 0.75741 to 0.76481, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1811 - accuracy: 0.9491 - val_loss: 0.8043 - val_accuracy: 0.7648\n",
      "Epoch 20/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9556\n",
      "Epoch 20: val_accuracy did not improve from 0.76481\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1604 - accuracy: 0.9558 - val_loss: 0.8669 - val_accuracy: 0.7435\n",
      "--- Running training session 3/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.29677999949201717, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 2.1556 - accuracy: 0.2346\n",
      "Epoch 1: val_accuracy improved from -inf to 0.28796, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 3s 15ms/step - loss: 2.1517 - accuracy: 0.2359 - val_loss: 1.9692 - val_accuracy: 0.2880\n",
      "Epoch 2/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.6452 - accuracy: 0.4200\n",
      "Epoch 2: val_accuracy improved from 0.28796 to 0.46019, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.6419 - accuracy: 0.4215 - val_loss: 1.5388 - val_accuracy: 0.4602\n",
      "Epoch 3/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.5077\n",
      "Epoch 3: val_accuracy improved from 0.46019 to 0.51019, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.3878 - accuracy: 0.5079 - val_loss: 1.3812 - val_accuracy: 0.5102\n",
      "Epoch 4/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.2258 - accuracy: 0.5591\n",
      "Epoch 4: val_accuracy improved from 0.51019 to 0.54815, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.2271 - accuracy: 0.5590 - val_loss: 1.3023 - val_accuracy: 0.5481\n",
      "Epoch 5/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.0739 - accuracy: 0.6234\n",
      "Epoch 5: val_accuracy improved from 0.54815 to 0.59537, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.0744 - accuracy: 0.6231 - val_loss: 1.1430 - val_accuracy: 0.5954\n",
      "Epoch 6/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.9620 - accuracy: 0.6727\n",
      "Epoch 6: val_accuracy did not improve from 0.59537\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.9616 - accuracy: 0.6727 - val_loss: 1.1671 - val_accuracy: 0.5880\n",
      "Epoch 7/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.8733 - accuracy: 0.7004\n",
      "Epoch 7: val_accuracy improved from 0.59537 to 0.61296, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.8742 - accuracy: 0.7000 - val_loss: 1.1539 - val_accuracy: 0.6130\n",
      "Epoch 8/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.7658 - accuracy: 0.7477\n",
      "Epoch 8: val_accuracy improved from 0.61296 to 0.65000, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.7655 - accuracy: 0.7479 - val_loss: 1.0279 - val_accuracy: 0.6500\n",
      "Epoch 9/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.7709\n",
      "Epoch 9: val_accuracy did not improve from 0.65000\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6912 - accuracy: 0.7713 - val_loss: 1.0808 - val_accuracy: 0.6306\n",
      "Epoch 10/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.7992\n",
      "Epoch 10: val_accuracy improved from 0.65000 to 0.67037, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6192 - accuracy: 0.7986 - val_loss: 0.9897 - val_accuracy: 0.6704\n",
      "Epoch 11/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.8073\n",
      "Epoch 11: val_accuracy improved from 0.67037 to 0.68796, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.5790 - accuracy: 0.8076 - val_loss: 0.9855 - val_accuracy: 0.6880\n",
      "Epoch 12/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8355\n",
      "Epoch 12: val_accuracy improved from 0.68796 to 0.69259, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.5052 - accuracy: 0.8356 - val_loss: 0.9461 - val_accuracy: 0.6926\n",
      "Epoch 13/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.8496\n",
      "Epoch 13: val_accuracy improved from 0.69259 to 0.70648, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4584 - accuracy: 0.8500 - val_loss: 0.9114 - val_accuracy: 0.7065\n",
      "Epoch 14/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8659\n",
      "Epoch 14: val_accuracy did not improve from 0.70648\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4161 - accuracy: 0.8644 - val_loss: 1.0451 - val_accuracy: 0.6741\n",
      "Epoch 15/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8797\n",
      "Epoch 15: val_accuracy improved from 0.70648 to 0.74537, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3671 - accuracy: 0.8794 - val_loss: 0.8379 - val_accuracy: 0.7454\n",
      "Epoch 16/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8939\n",
      "Epoch 16: val_accuracy did not improve from 0.74537\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3414 - accuracy: 0.8938 - val_loss: 0.9546 - val_accuracy: 0.6935\n",
      "Epoch 17/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.9007\n",
      "Epoch 17: val_accuracy did not improve from 0.74537\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3106 - accuracy: 0.9009 - val_loss: 1.0085 - val_accuracy: 0.6991\n",
      "Epoch 18/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.2658 - accuracy: 0.9195\n",
      "Epoch 18: val_accuracy did not improve from 0.74537\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.2665 - accuracy: 0.9190 - val_loss: 1.0469 - val_accuracy: 0.6861\n",
      "Epoch 19/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9214\n",
      "Epoch 19: val_accuracy did not improve from 0.74537\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2514 - accuracy: 0.9213 - val_loss: 1.0493 - val_accuracy: 0.6944\n",
      "Epoch 20/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9325\n",
      "Epoch 20: val_accuracy did not improve from 0.74537\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2180 - accuracy: 0.9326 - val_loss: 0.9688 - val_accuracy: 0.7204\n",
      "--- Running training session 4/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 2, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.29677999949201717, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 2.1502 - accuracy: 0.2434\n",
      "Epoch 1: val_accuracy improved from -inf to 0.34074, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 3s 14ms/step - loss: 2.1450 - accuracy: 0.2449 - val_loss: 1.9373 - val_accuracy: 0.3407\n",
      "Epoch 2/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.6275 - accuracy: 0.4269\n",
      "Epoch 2: val_accuracy improved from 0.34074 to 0.48889, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.6256 - accuracy: 0.4273 - val_loss: 1.4686 - val_accuracy: 0.4889\n",
      "Epoch 3/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 1.3673 - accuracy: 0.5229\n",
      "Epoch 3: val_accuracy improved from 0.48889 to 0.54630, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.3671 - accuracy: 0.5234 - val_loss: 1.3018 - val_accuracy: 0.5463\n",
      "Epoch 4/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 1.1906 - accuracy: 0.5881\n",
      "Epoch 4: val_accuracy did not improve from 0.54630\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.1908 - accuracy: 0.5884 - val_loss: 1.3197 - val_accuracy: 0.5333\n",
      "Epoch 5/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.0494 - accuracy: 0.6454\n",
      "Epoch 5: val_accuracy improved from 0.54630 to 0.55926, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.0481 - accuracy: 0.6463 - val_loss: 1.2637 - val_accuracy: 0.5593\n",
      "Epoch 6/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.9365 - accuracy: 0.6853\n",
      "Epoch 6: val_accuracy improved from 0.55926 to 0.64444, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.9423 - accuracy: 0.6840 - val_loss: 1.0374 - val_accuracy: 0.6444\n",
      "Epoch 7/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.8302 - accuracy: 0.7232\n",
      "Epoch 7: val_accuracy did not improve from 0.64444\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.8292 - accuracy: 0.7231 - val_loss: 1.0570 - val_accuracy: 0.6380\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.7495\n",
      "Epoch 8: val_accuracy improved from 0.64444 to 0.65741, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.7445 - accuracy: 0.7495 - val_loss: 1.0301 - val_accuracy: 0.6574\n",
      "Epoch 9/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.6618 - accuracy: 0.7836\n",
      "Epoch 9: val_accuracy improved from 0.65741 to 0.71759, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.6612 - accuracy: 0.7838 - val_loss: 0.8498 - val_accuracy: 0.7176\n",
      "Epoch 10/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.6142 - accuracy: 0.8037\n",
      "Epoch 10: val_accuracy did not improve from 0.71759\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6148 - accuracy: 0.8028 - val_loss: 0.8494 - val_accuracy: 0.7157\n",
      "Epoch 11/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.5253 - accuracy: 0.8298\n",
      "Epoch 11: val_accuracy improved from 0.71759 to 0.72407, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.5292 - accuracy: 0.8285 - val_loss: 0.8456 - val_accuracy: 0.7241\n",
      "Epoch 12/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8520\n",
      "Epoch 12: val_accuracy did not improve from 0.72407\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4768 - accuracy: 0.8530 - val_loss: 0.9253 - val_accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8593\n",
      "Epoch 13: val_accuracy improved from 0.72407 to 0.72963, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4394 - accuracy: 0.8593 - val_loss: 0.8367 - val_accuracy: 0.7296\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8801\n",
      "Epoch 14: val_accuracy improved from 0.72963 to 0.75926, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3873 - accuracy: 0.8801 - val_loss: 0.7278 - val_accuracy: 0.7593\n",
      "Epoch 15/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8872\n",
      "Epoch 15: val_accuracy did not improve from 0.75926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3472 - accuracy: 0.8875 - val_loss: 0.7769 - val_accuracy: 0.7463\n",
      "Epoch 16/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.8973\n",
      "Epoch 16: val_accuracy did not improve from 0.75926\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3254 - accuracy: 0.8975 - val_loss: 0.8993 - val_accuracy: 0.7167\n",
      "Epoch 17/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9069\n",
      "Epoch 17: val_accuracy did not improve from 0.75926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2863 - accuracy: 0.9069 - val_loss: 0.8325 - val_accuracy: 0.7352\n",
      "Epoch 18/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9195\n",
      "Epoch 18: val_accuracy improved from 0.75926 to 0.78148, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2505 - accuracy: 0.9206 - val_loss: 0.7599 - val_accuracy: 0.7815\n",
      "Epoch 19/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9321\n",
      "Epoch 19: val_accuracy did not improve from 0.78148\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2257 - accuracy: 0.9317 - val_loss: 0.8315 - val_accuracy: 0.7509\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9419\n",
      "Epoch 20: val_accuracy did not improve from 0.78148\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2014 - accuracy: 0.9419 - val_loss: 0.8200 - val_accuracy: 0.7444\n",
      "--- Running training session 5/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.21392737051981528, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 22:08:29.554541: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - ETA: 0s - loss: 2.0466 - accuracy: 0.2722\n",
      "Epoch 1: val_accuracy improved from -inf to 0.30741, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 5s 15ms/step - loss: 2.0466 - accuracy: 0.2722 - val_loss: 1.9267 - val_accuracy: 0.3074\n",
      "Epoch 2/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.4442 - accuracy: 0.5056\n",
      "Epoch 2: val_accuracy improved from 0.30741 to 0.53241, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.4427 - accuracy: 0.5058 - val_loss: 1.4136 - val_accuracy: 0.5324\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.1384 - accuracy: 0.6146\n",
      "Epoch 3: val_accuracy did not improve from 0.53241\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.1384 - accuracy: 0.6146 - val_loss: 1.3436 - val_accuracy: 0.5222\n",
      "Epoch 4/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.8751 - accuracy: 0.7019\n",
      "Epoch 4: val_accuracy improved from 0.53241 to 0.59815, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.8706 - accuracy: 0.7035 - val_loss: 1.3427 - val_accuracy: 0.5981\n",
      "Epoch 5/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.7129 - accuracy: 0.7575\n",
      "Epoch 5: val_accuracy improved from 0.59815 to 0.63796, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.7112 - accuracy: 0.7581 - val_loss: 1.1785 - val_accuracy: 0.6380\n",
      "Epoch 6/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.5738 - accuracy: 0.8092\n",
      "Epoch 6: val_accuracy improved from 0.63796 to 0.65926, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 15ms/step - loss: 0.5740 - accuracy: 0.8086 - val_loss: 1.2088 - val_accuracy: 0.6593\n",
      "Epoch 7/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.8390\n",
      "Epoch 7: val_accuracy did not improve from 0.65926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4763 - accuracy: 0.8400 - val_loss: 1.8552 - val_accuracy: 0.5472\n",
      "Epoch 8/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.4159 - accuracy: 0.8612\n",
      "Epoch 8: val_accuracy did not improve from 0.65926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4122 - accuracy: 0.8627 - val_loss: 1.4610 - val_accuracy: 0.6185\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8977\n",
      "Epoch 9: val_accuracy did not improve from 0.65926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3159 - accuracy: 0.8977 - val_loss: 1.5580 - val_accuracy: 0.6509\n",
      "Epoch 10/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.9027\n",
      "Epoch 10: val_accuracy did not improve from 0.65926\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3048 - accuracy: 0.9025 - val_loss: 1.4866 - val_accuracy: 0.6407\n",
      "Epoch 11/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9185\n",
      "Epoch 11: val_accuracy did not improve from 0.65926\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2584 - accuracy: 0.9187 - val_loss: 2.2674 - val_accuracy: 0.5722\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9301\n",
      "Epoch 12: val_accuracy improved from 0.65926 to 0.70093, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2204 - accuracy: 0.9301 - val_loss: 1.2643 - val_accuracy: 0.7009\n",
      "Epoch 13/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9427\n",
      "Epoch 13: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1752 - accuracy: 0.9433 - val_loss: 1.6318 - val_accuracy: 0.6556\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9419\n",
      "Epoch 14: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.1805 - accuracy: 0.9419 - val_loss: 1.5174 - val_accuracy: 0.6944\n",
      "Epoch 15/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9506\n",
      "Epoch 15: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1566 - accuracy: 0.9509 - val_loss: 1.7405 - val_accuracy: 0.6519\n",
      "Epoch 16/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9602\n",
      "Epoch 16: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1314 - accuracy: 0.9595 - val_loss: 1.8138 - val_accuracy: 0.6722\n",
      "Epoch 17/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9557\n",
      "Epoch 17: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1437 - accuracy: 0.9556 - val_loss: 2.2296 - val_accuracy: 0.6481\n",
      "Epoch 18/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9578\n",
      "Epoch 18: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1304 - accuracy: 0.9579 - val_loss: 1.6012 - val_accuracy: 0.6870\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9648\n",
      "Epoch 19: val_accuracy did not improve from 0.70093\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1197 - accuracy: 0.9648 - val_loss: 1.7752 - val_accuracy: 0.6870\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9618\n",
      "Epoch 20: val_accuracy improved from 0.70093 to 0.71667, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1246 - accuracy: 0.9618 - val_loss: 1.3943 - val_accuracy: 0.7167\n",
      "--- Running training session 6/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.21392737051981528, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 2.0052 - accuracy: 0.2711\n",
      "Epoch 1: val_accuracy improved from -inf to 0.30556, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 5s 17ms/step - loss: 2.0028 - accuracy: 0.2727 - val_loss: 1.8826 - val_accuracy: 0.3056\n",
      "Epoch 2/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 1.4475 - accuracy: 0.4763\n",
      "Epoch 2: val_accuracy improved from 0.30556 to 0.55833, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.4479 - accuracy: 0.4773 - val_loss: 1.2538 - val_accuracy: 0.5583\n",
      "Epoch 3/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 1.1691 - accuracy: 0.5862\n",
      "Epoch 3: val_accuracy did not improve from 0.55833\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.1672 - accuracy: 0.5859 - val_loss: 1.9941 - val_accuracy: 0.4426\n",
      "Epoch 4/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.9303 - accuracy: 0.6690\n",
      "Epoch 4: val_accuracy improved from 0.55833 to 0.66667, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.9291 - accuracy: 0.6711 - val_loss: 1.0214 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.7372 - accuracy: 0.7448\n",
      "Epoch 5: val_accuracy did not improve from 0.66667\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.7343 - accuracy: 0.7461 - val_loss: 1.1561 - val_accuracy: 0.6389\n",
      "Epoch 6/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.5909 - accuracy: 0.8009\n",
      "Epoch 6: val_accuracy improved from 0.66667 to 0.68519, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.5901 - accuracy: 0.8019 - val_loss: 1.0613 - val_accuracy: 0.6852\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8426\n",
      "Epoch 7: val_accuracy did not improve from 0.68519\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4710 - accuracy: 0.8426 - val_loss: 1.3574 - val_accuracy: 0.6296\n",
      "Epoch 8/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.4058 - accuracy: 0.8628\n",
      "Epoch 8: val_accuracy did not improve from 0.68519\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4061 - accuracy: 0.8627 - val_loss: 1.2818 - val_accuracy: 0.6602\n",
      "Epoch 9/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8885\n",
      "Epoch 9: val_accuracy did not improve from 0.68519\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3384 - accuracy: 0.8877 - val_loss: 1.2340 - val_accuracy: 0.6833\n",
      "Epoch 10/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.9081\n",
      "Epoch 10: val_accuracy did not improve from 0.68519\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2837 - accuracy: 0.9081 - val_loss: 1.2898 - val_accuracy: 0.6685\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9213\n",
      "Epoch 11: val_accuracy improved from 0.68519 to 0.74352, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2457 - accuracy: 0.9213 - val_loss: 1.0621 - val_accuracy: 0.7435\n",
      "Epoch 12/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9303\n",
      "Epoch 12: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2196 - accuracy: 0.9301 - val_loss: 1.4169 - val_accuracy: 0.6815\n",
      "Epoch 13/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9389\n",
      "Epoch 13: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1837 - accuracy: 0.9391 - val_loss: 1.5359 - val_accuracy: 0.6907\n",
      "Epoch 14/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9466\n",
      "Epoch 14: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1674 - accuracy: 0.9468 - val_loss: 1.5189 - val_accuracy: 0.6898\n",
      "Epoch 15/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9531\n",
      "Epoch 15: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1478 - accuracy: 0.9535 - val_loss: 1.7737 - val_accuracy: 0.6787\n",
      "Epoch 16/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9621\n",
      "Epoch 16: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1200 - accuracy: 0.9625 - val_loss: 2.2523 - val_accuracy: 0.6556\n",
      "Epoch 17/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9566\n",
      "Epoch 17: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1344 - accuracy: 0.9565 - val_loss: 1.2427 - val_accuracy: 0.7380\n",
      "Epoch 18/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9619\n",
      "Epoch 18: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1228 - accuracy: 0.9611 - val_loss: 1.5780 - val_accuracy: 0.6944\n",
      "Epoch 19/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9592\n",
      "Epoch 19: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1253 - accuracy: 0.9595 - val_loss: 1.8683 - val_accuracy: 0.6648\n",
      "Epoch 20/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9737\n",
      "Epoch 20: val_accuracy did not improve from 0.74352\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.0821 - accuracy: 0.9741 - val_loss: 1.4603 - val_accuracy: 0.7241\n",
      "--- Running training session 7/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.2799402574081021, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.9884 - accuracy: 0.2789\n",
      "Epoch 1: val_accuracy improved from -inf to 0.30278, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 5s 16ms/step - loss: 1.9884 - accuracy: 0.2789 - val_loss: 1.9357 - val_accuracy: 0.3028\n",
      "Epoch 2/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.4815 - accuracy: 0.4727\n",
      "Epoch 2: val_accuracy improved from 0.30278 to 0.46574, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 1.4829 - accuracy: 0.4725 - val_loss: 1.5205 - val_accuracy: 0.4657\n",
      "Epoch 3/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.1962 - accuracy: 0.5767\n",
      "Epoch 3: val_accuracy improved from 0.46574 to 0.59630, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 1.1919 - accuracy: 0.5773 - val_loss: 1.2137 - val_accuracy: 0.5963\n",
      "Epoch 4/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.9867 - accuracy: 0.6710\n",
      "Epoch 4: val_accuracy did not improve from 0.59630\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.9841 - accuracy: 0.6729 - val_loss: 1.3474 - val_accuracy: 0.5667\n",
      "Epoch 5/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.8244 - accuracy: 0.7188\n",
      "Epoch 5: val_accuracy did not improve from 0.59630\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.8222 - accuracy: 0.7201 - val_loss: 1.2876 - val_accuracy: 0.5852\n",
      "Epoch 6/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.6668 - accuracy: 0.7770\n",
      "Epoch 6: val_accuracy improved from 0.59630 to 0.60741, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.6660 - accuracy: 0.7778 - val_loss: 1.2878 - val_accuracy: 0.6074\n",
      "Epoch 7/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8151\n",
      "Epoch 7: val_accuracy improved from 0.60741 to 0.68796, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.5561 - accuracy: 0.8155 - val_loss: 1.0287 - val_accuracy: 0.6880\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8428\n",
      "Epoch 8: val_accuracy did not improve from 0.68796\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.4731 - accuracy: 0.8428 - val_loss: 1.9077 - val_accuracy: 0.5139\n",
      "Epoch 9/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8740\n",
      "Epoch 9: val_accuracy did not improve from 0.68796\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3884 - accuracy: 0.8745 - val_loss: 1.2125 - val_accuracy: 0.6843\n",
      "Epoch 10/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8957\n",
      "Epoch 10: val_accuracy did not improve from 0.68796\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3246 - accuracy: 0.8963 - val_loss: 1.3101 - val_accuracy: 0.6602\n",
      "Epoch 11/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.9036\n",
      "Epoch 11: val_accuracy improved from 0.68796 to 0.70000, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2977 - accuracy: 0.9030 - val_loss: 1.1851 - val_accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.9227\n",
      "Epoch 12: val_accuracy improved from 0.70000 to 0.71389, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2433 - accuracy: 0.9227 - val_loss: 1.1368 - val_accuracy: 0.7139\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9354\n",
      "Epoch 13: val_accuracy did not improve from 0.71389\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2000 - accuracy: 0.9354 - val_loss: 1.4477 - val_accuracy: 0.7000\n",
      "Epoch 14/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9321\n",
      "Epoch 14: val_accuracy did not improve from 0.71389\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2036 - accuracy: 0.9322 - val_loss: 1.8472 - val_accuracy: 0.6583\n",
      "Epoch 15/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9334\n",
      "Epoch 15: val_accuracy did not improve from 0.71389\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1977 - accuracy: 0.9324 - val_loss: 1.8745 - val_accuracy: 0.6657\n",
      "Epoch 16/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9487\n",
      "Epoch 16: val_accuracy did not improve from 0.71389\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.1614 - accuracy: 0.9493 - val_loss: 1.4502 - val_accuracy: 0.7120\n",
      "Epoch 17/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9457\n",
      "Epoch 17: val_accuracy improved from 0.71389 to 0.71667, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.1773 - accuracy: 0.9454 - val_loss: 1.3207 - val_accuracy: 0.7167\n",
      "Epoch 18/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9524\n",
      "Epoch 18: val_accuracy did not improve from 0.71667\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1553 - accuracy: 0.9523 - val_loss: 1.5284 - val_accuracy: 0.6917\n",
      "Epoch 19/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9568\n",
      "Epoch 19: val_accuracy improved from 0.71667 to 0.73704, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.1206 - accuracy: 0.9569 - val_loss: 1.3047 - val_accuracy: 0.7370\n",
      "Epoch 20/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9530\n",
      "Epoch 20: val_accuracy did not improve from 0.73704\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.1447 - accuracy: 0.9535 - val_loss: 1.5587 - val_accuracy: 0.7093\n",
      "--- Running training session 8/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 32, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 3, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.2799402574081021, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'adam'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 2.0162 - accuracy: 0.2655\n",
      "Epoch 1: val_accuracy improved from -inf to 0.29722, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 6s 17ms/step - loss: 2.0119 - accuracy: 0.2667 - val_loss: 1.8815 - val_accuracy: 0.2972\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.4859\n",
      "Epoch 2: val_accuracy improved from 0.29722 to 0.55000, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 1.4686 - accuracy: 0.4859 - val_loss: 1.3708 - val_accuracy: 0.5500\n",
      "Epoch 3/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 1.1995 - accuracy: 0.5872\n",
      "Epoch 3: val_accuracy improved from 0.55000 to 0.58426, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 1.1987 - accuracy: 0.5868 - val_loss: 1.1846 - val_accuracy: 0.5843\n",
      "Epoch 4/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.9626 - accuracy: 0.6611\n",
      "Epoch 4: val_accuracy did not improve from 0.58426\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.9609 - accuracy: 0.6620 - val_loss: 1.4689 - val_accuracy: 0.5444\n",
      "Epoch 5/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.8143 - accuracy: 0.7263\n",
      "Epoch 5: val_accuracy improved from 0.58426 to 0.62315, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.8129 - accuracy: 0.7252 - val_loss: 1.2821 - val_accuracy: 0.6231\n",
      "Epoch 6/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.6654 - accuracy: 0.7733\n",
      "Epoch 6: val_accuracy improved from 0.62315 to 0.66389, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.6641 - accuracy: 0.7738 - val_loss: 1.0856 - val_accuracy: 0.6639\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8282\n",
      "Epoch 7: val_accuracy did not improve from 0.66389\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.5184 - accuracy: 0.8282 - val_loss: 1.3467 - val_accuracy: 0.6093\n",
      "Epoch 8/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.4537 - accuracy: 0.8516\n",
      "Epoch 8: val_accuracy did not improve from 0.66389\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4534 - accuracy: 0.8509 - val_loss: 1.2414 - val_accuracy: 0.6620\n",
      "Epoch 9/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.4043 - accuracy: 0.8708\n",
      "Epoch 9: val_accuracy improved from 0.66389 to 0.68889, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.4019 - accuracy: 0.8715 - val_loss: 1.0631 - val_accuracy: 0.6889\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8789\n",
      "Epoch 10: val_accuracy did not improve from 0.68889\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.3628 - accuracy: 0.8789 - val_loss: 1.4924 - val_accuracy: 0.6528\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9044\n",
      "Epoch 11: val_accuracy improved from 0.68889 to 0.71204, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2789 - accuracy: 0.9044 - val_loss: 1.1580 - val_accuracy: 0.7120\n",
      "Epoch 12/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.9170\n",
      "Epoch 12: val_accuracy improved from 0.71204 to 0.71296, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.2515 - accuracy: 0.9174 - val_loss: 1.3250 - val_accuracy: 0.7130\n",
      "Epoch 13/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.9292\n",
      "Epoch 13: val_accuracy improved from 0.71296 to 0.71389, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2300 - accuracy: 0.9285 - val_loss: 1.3157 - val_accuracy: 0.7139\n",
      "Epoch 14/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9349\n",
      "Epoch 14: val_accuracy improved from 0.71389 to 0.72315, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2001 - accuracy: 0.9354 - val_loss: 1.3501 - val_accuracy: 0.7231\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9461\n",
      "Epoch 15: val_accuracy did not improve from 0.72315\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1791 - accuracy: 0.9461 - val_loss: 1.5672 - val_accuracy: 0.6824\n",
      "Epoch 16/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9380\n",
      "Epoch 16: val_accuracy did not improve from 0.72315\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1940 - accuracy: 0.9380 - val_loss: 1.2638 - val_accuracy: 0.7185\n",
      "Epoch 17/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9453\n",
      "Epoch 17: val_accuracy did not improve from 0.72315\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1727 - accuracy: 0.9451 - val_loss: 1.5268 - val_accuracy: 0.7065\n",
      "Epoch 18/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9528\n",
      "Epoch 18: val_accuracy improved from 0.72315 to 0.73148, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 14ms/step - loss: 0.1470 - accuracy: 0.9530 - val_loss: 1.4814 - val_accuracy: 0.7315\n",
      "Epoch 19/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9522\n",
      "Epoch 19: val_accuracy did not improve from 0.73148\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1566 - accuracy: 0.9509 - val_loss: 1.6849 - val_accuracy: 0.6917\n",
      "Epoch 20/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9635\n",
      "Epoch 20: val_accuracy did not improve from 0.73148\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.1137 - accuracy: 0.9641 - val_loss: 1.8964 - val_accuracy: 0.6833\n",
      "--- Running training session 9/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.27298317482601286, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 1\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 2.0665 - accuracy: 0.3086\n",
      "Epoch 1: val_accuracy improved from -inf to 0.29630, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 3s 14ms/step - loss: 2.0665 - accuracy: 0.3086 - val_loss: 2.0305 - val_accuracy: 0.2963\n",
      "Epoch 2/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.4163 - accuracy: 0.4981\n",
      "Epoch 2: val_accuracy improved from 0.29630 to 0.51296, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.4154 - accuracy: 0.4993 - val_loss: 1.3687 - val_accuracy: 0.5130\n",
      "Epoch 3/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 1.1752 - accuracy: 0.5861\n",
      "Epoch 3: val_accuracy improved from 0.51296 to 0.60556, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.1763 - accuracy: 0.5866 - val_loss: 1.0884 - val_accuracy: 0.6056\n",
      "Epoch 4/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 1.0179 - accuracy: 0.6512\n",
      "Epoch 4: val_accuracy did not improve from 0.60556\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 1.0151 - accuracy: 0.6525 - val_loss: 1.1381 - val_accuracy: 0.5972\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.8932 - accuracy: 0.6903\n",
      "Epoch 5: val_accuracy improved from 0.60556 to 0.66944, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.8932 - accuracy: 0.6903 - val_loss: 0.9757 - val_accuracy: 0.6694\n",
      "Epoch 6/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.7794 - accuracy: 0.7322\n",
      "Epoch 6: val_accuracy did not improve from 0.66944\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.7787 - accuracy: 0.7326 - val_loss: 0.9682 - val_accuracy: 0.6620\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.7214 - accuracy: 0.7565\n",
      "Epoch 7: val_accuracy improved from 0.66944 to 0.69537, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.7214 - accuracy: 0.7565 - val_loss: 0.8969 - val_accuracy: 0.6954\n",
      "Epoch 8/20\n",
      "130/135 [===========================>..] - ETA: 0s - loss: 0.6303 - accuracy: 0.7933\n",
      "Epoch 8: val_accuracy improved from 0.69537 to 0.70556, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6270 - accuracy: 0.7937 - val_loss: 0.9228 - val_accuracy: 0.7056\n",
      "Epoch 9/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.5811 - accuracy: 0.8038\n",
      "Epoch 9: val_accuracy did not improve from 0.70556\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.5806 - accuracy: 0.8039 - val_loss: 0.9953 - val_accuracy: 0.6843\n",
      "Epoch 10/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.5457 - accuracy: 0.8165\n",
      "Epoch 10: val_accuracy improved from 0.70556 to 0.72407, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.5444 - accuracy: 0.8167 - val_loss: 0.8419 - val_accuracy: 0.7241\n",
      "Epoch 11/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.8345\n",
      "Epoch 11: val_accuracy improved from 0.72407 to 0.72500, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4903 - accuracy: 0.8350 - val_loss: 0.8450 - val_accuracy: 0.7250\n",
      "Epoch 12/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.8547\n",
      "Epoch 12: val_accuracy improved from 0.72500 to 0.73056, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4539 - accuracy: 0.8544 - val_loss: 0.8537 - val_accuracy: 0.7306\n",
      "Epoch 13/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.4003 - accuracy: 0.8708\n",
      "Epoch 13: val_accuracy did not improve from 0.73056\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3990 - accuracy: 0.8718 - val_loss: 0.8621 - val_accuracy: 0.7287\n",
      "Epoch 14/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.3745 - accuracy: 0.8748\n",
      "Epoch 14: val_accuracy did not improve from 0.73056\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3736 - accuracy: 0.8750 - val_loss: 0.9381 - val_accuracy: 0.7241\n",
      "Epoch 15/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8902\n",
      "Epoch 15: val_accuracy did not improve from 0.73056\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3413 - accuracy: 0.8887 - val_loss: 1.3433 - val_accuracy: 0.6333\n",
      "Epoch 16/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.3131 - accuracy: 0.9025\n",
      "Epoch 16: val_accuracy did not improve from 0.73056\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3134 - accuracy: 0.9025 - val_loss: 0.8724 - val_accuracy: 0.7250\n",
      "Epoch 17/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.9022\n",
      "Epoch 17: val_accuracy improved from 0.73056 to 0.73426, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3086 - accuracy: 0.9019 - val_loss: 0.8518 - val_accuracy: 0.7343\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9058\n",
      "Epoch 18: val_accuracy did not improve from 0.73426\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2924 - accuracy: 0.9058 - val_loss: 0.9762 - val_accuracy: 0.7083\n",
      "Epoch 19/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9207\n",
      "Epoch 19: val_accuracy improved from 0.73426 to 0.73519, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2519 - accuracy: 0.9211 - val_loss: 0.9015 - val_accuracy: 0.7352\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9201\n",
      "Epoch 20: val_accuracy improved from 0.73519 to 0.75556, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2461 - accuracy: 0.9201 - val_loss: 0.8443 - val_accuracy: 0.7556\n",
      "--- Running training session 10/10\n",
      "{HParam(name='num_units', domain=Discrete([32, 64]), display_name=None, description=None): 64, HParam(name='dense_layers', domain=IntInterval(1, 3), display_name=None, description=None): 1, HParam(name='dropout', domain=RealInterval(0.2, 0.3), display_name=None, description=None): 0.27298317482601286, HParam(name='optimizer', domain=Discrete(['adam', 'sgd']), display_name=None, description=None): 'sgd'}\n",
      "--- repeat #: 2\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 2.1329 - accuracy: 0.2986\n",
      "Epoch 1: val_accuracy improved from -inf to 0.31111, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 3s 15ms/step - loss: 2.1329 - accuracy: 0.2986 - val_loss: 1.9421 - val_accuracy: 0.3111\n",
      "Epoch 2/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 1.4860 - accuracy: 0.4867\n",
      "Epoch 2: val_accuracy improved from 0.31111 to 0.53333, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.4826 - accuracy: 0.4873 - val_loss: 1.3358 - val_accuracy: 0.5333\n",
      "Epoch 3/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 1.2012 - accuracy: 0.5685\n",
      "Epoch 3: val_accuracy did not improve from 0.53333\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 1.1978 - accuracy: 0.5708 - val_loss: 1.3501 - val_accuracy: 0.5194\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.0256 - accuracy: 0.6560\n",
      "Epoch 4: val_accuracy improved from 0.53333 to 0.57130, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 1.0256 - accuracy: 0.6560 - val_loss: 1.2195 - val_accuracy: 0.5713\n",
      "Epoch 5/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.9069 - accuracy: 0.6842\n",
      "Epoch 5: val_accuracy did not improve from 0.57130\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.9058 - accuracy: 0.6836 - val_loss: 1.4280 - val_accuracy: 0.5259\n",
      "Epoch 6/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.8074 - accuracy: 0.7271\n",
      "Epoch 6: val_accuracy did not improve from 0.57130\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.8089 - accuracy: 0.7280 - val_loss: 1.3360 - val_accuracy: 0.5639\n",
      "Epoch 7/20\n",
      "133/135 [============================>.] - ETA: 0s - loss: 0.7249 - accuracy: 0.7561\n",
      "Epoch 7: val_accuracy improved from 0.57130 to 0.60093, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.7231 - accuracy: 0.7567 - val_loss: 1.1658 - val_accuracy: 0.6009\n",
      "Epoch 8/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.6411 - accuracy: 0.7851\n",
      "Epoch 8: val_accuracy improved from 0.60093 to 0.67037, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.6417 - accuracy: 0.7847 - val_loss: 0.9725 - val_accuracy: 0.6704\n",
      "Epoch 9/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.8059\n",
      "Epoch 9: val_accuracy did not improve from 0.67037\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.5806 - accuracy: 0.8062 - val_loss: 1.1436 - val_accuracy: 0.6167\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.8361\n",
      "Epoch 10: val_accuracy did not improve from 0.67037\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.5158 - accuracy: 0.8361 - val_loss: 1.0315 - val_accuracy: 0.6519\n",
      "Epoch 11/20\n",
      "129/135 [===========================>..] - ETA: 0s - loss: 0.4737 - accuracy: 0.8442\n",
      "Epoch 11: val_accuracy did not improve from 0.67037\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.4766 - accuracy: 0.8435 - val_loss: 1.1979 - val_accuracy: 0.6176\n",
      "Epoch 12/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.8653\n",
      "Epoch 12: val_accuracy improved from 0.67037 to 0.67593, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.4199 - accuracy: 0.8655 - val_loss: 0.9942 - val_accuracy: 0.6759\n",
      "Epoch 13/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8717\n",
      "Epoch 13: val_accuracy improved from 0.67593 to 0.72407, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3926 - accuracy: 0.8725 - val_loss: 0.8797 - val_accuracy: 0.7241\n",
      "Epoch 14/20\n",
      "132/135 [============================>.] - ETA: 0s - loss: 0.3685 - accuracy: 0.8826\n",
      "Epoch 14: val_accuracy improved from 0.72407 to 0.72963, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3682 - accuracy: 0.8826 - val_loss: 0.8280 - val_accuracy: 0.7296\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8977\n",
      "Epoch 15: val_accuracy improved from 0.72963 to 0.73333, saving model to logs/checkpoint\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.3229 - accuracy: 0.8977 - val_loss: 0.8560 - val_accuracy: 0.7333\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.8947\n",
      "Epoch 16: val_accuracy did not improve from 0.73333\n",
      "135/135 [==============================] - 2s 11ms/step - loss: 0.3179 - accuracy: 0.8947 - val_loss: 0.8847 - val_accuracy: 0.7139\n",
      "Epoch 17/20\n",
      "131/135 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9134\n",
      "Epoch 17: val_accuracy did not improve from 0.73333\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.2781 - accuracy: 0.9127 - val_loss: 0.9089 - val_accuracy: 0.7269\n",
      "Epoch 18/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.9139\n",
      "Epoch 18: val_accuracy did not improve from 0.73333\n",
      "135/135 [==============================] - 2s 13ms/step - loss: 0.2601 - accuracy: 0.9144 - val_loss: 0.9866 - val_accuracy: 0.7009\n",
      "Epoch 19/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9307\n",
      "Epoch 19: val_accuracy did not improve from 0.73333\n",
      "135/135 [==============================] - 1s 11ms/step - loss: 0.2239 - accuracy: 0.9310 - val_loss: 0.9338 - val_accuracy: 0.7315\n",
      "Epoch 20/20\n",
      "134/135 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9312\n",
      "Epoch 20: val_accuracy did not improve from 0.73333\n",
      "135/135 [==============================] - 2s 12ms/step - loss: 0.2282 - accuracy: 0.9312 - val_loss: 1.0719 - val_accuracy: 0.7000\n",
      "Done. Output saved to logs/hparam_tuning/\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "np.random.seed(0)\n",
    "logdir = LOGDIR\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "print(f\"Saving output to {logdir}\")\n",
    "model = run_all(logdir=logdir, verbose=True)\n",
    "print(f\"Done. Output saved to {logdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e07727f838a93778\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e07727f838a93778\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from checkpoint\n",
    "\n",
    "model.load_weights(CHECKPOINT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
